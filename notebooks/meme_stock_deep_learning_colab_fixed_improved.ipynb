{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\ude80 Meme Stock Price Prediction with Deep Learning (A100 GPU Optimized)\n",
        "\n",
        "**Fixed version for Colab A100 GPU with robust LSTM data loading**\n",
        "\n",
        "## Overview\n",
        "This notebook implements state-of-the-art deep learning models to predict meme stock price movements using:\n",
        "- **Technical indicators** (price, volume, volatility)\n",
        "- **Reddit sentiment features** (mentions, surprises, market sentiment)\n",
        "- **Time series patterns** (momentum, regimes, interactions)\n",
        "\n",
        "## Key Fixes for A100 GPU\n",
        "1. **LSTM Data Loading**: Robust handling of string data types\n",
        "2. **GPU Optimization**: Mixed precision training (FP16)\n",
        "3. **Error Handling**: Fallback mechanisms for sequence models\n",
        "4. **Memory Management**: A100 40GB+ memory utilization\n",
        "\n",
        "## Success Criteria\n",
        "- **IC improvement** \u2265 0.03 vs price-only baseline\n",
        "- **Information Ratio (IR)** \u2265 0.3\n",
        "- **Hit Rate** > 55%\n",
        "- **Statistical significance** (p < 0.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\udee0\ufe0f Setup and Package Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_packages"
      },
      "outputs": [],
      "source": [
        "# Install required packages for A100 GPU\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_packages():\n",
        "    \"\"\"Install required packages for A100 GPU\"\"\"\n",
        "    packages = [\n",
        "        \"pytorch-tabnet\",\n",
        "        \"transformers\", \n",
        "        \"optuna\",\n",
        "        \"plotly\",\n",
        "        \"seaborn\"\n",
        "    ]\n",
        "    \n",
        "    for package in packages:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "            print(f\"\u2705 {package} installed successfully\")\n",
        "        except:\n",
        "            print(f\"\u26a0\ufe0f Failed to install {package}\")\n",
        "\n",
        "# Install packages\n",
        "install_packages()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\udcda Import Libraries and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_libraries"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ML libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.metrics import mean_squared_error, classification_report\n",
        "from scipy.stats import spearmanr, pearsonr\n",
        "import optuna\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "\n",
        "# A100 GPU \ucd5c\uc801\ud654\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "# Set random seeds\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "print(\"\u2705 Libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\ude80 A100 GPU Optimization Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu_setup"
      },
      "outputs": [],
      "source": [
        "def setup_a100_optimization():\n",
        "    \"\"\"A100 GPU \ucd5c\uc801\ud654 \uc124\uc815\"\"\"\n",
        "    \n",
        "    # Set device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    if device.type == 'cuda':\n",
        "        print(f\"\ud83d\ude80 Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "        \n",
        "        # A100 \ucd5c\uc801\ud654 \uc124\uc815\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.backends.cudnn.deterministic = False\n",
        "        \n",
        "        # \uba54\ubaa8\ub9ac \ud6a8\uc728\uc131 (A100 \uba54\ubaa8\ub9ac 40GB+ \ud65c\uc6a9)\n",
        "        torch.cuda.set_per_process_memory_fraction(0.95)\n",
        "        \n",
        "        # GPU \uba54\ubaa8\ub9ac \uc815\ub9ac\n",
        "        torch.cuda.empty_cache()\n",
        "    else:\n",
        "        print(\"\ud83d\udcbb Using CPU\")\n",
        "    \n",
        "    return device\n",
        "\n",
        "# Setup GPU\n",
        "device = setup_a100_optimization()\n",
        "\n",
        "# Initialize mixed precision training\n",
        "scaler = GradScaler()\n",
        "print(\"\u2705 A100 GPU optimization setup completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\udce4 Data Upload (Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload_data"
      },
      "outputs": [],
      "source": [
        "def upload_data_colab():\n",
        "    \"\"\"Colab\uc5d0\uc11c \ub370\uc774\ud130 \uc5c5\ub85c\ub4dc\"\"\"\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        \n",
        "        print(\"\ud83d\udce4 Upload the following files from your local machine:\")\n",
        "        print(\"   - tabular_train_YYYYMMDD_HHMMSS.csv\")\n",
        "        print(\"   - tabular_val_YYYYMMDD_HHMMSS.csv\") \n",
        "        print(\"   - tabular_test_YYYYMMDD_HHMMSS.csv\")\n",
        "        print(\"   - sequences_YYYYMMDD_HHMMSS.npz\")\n",
        "        print(\"   - dataset_metadata_YYYYMMDD_HHMMSS.json\")\n",
        "        \n",
        "        uploaded = files.upload()\n",
        "        \n",
        "        # Show uploaded files\n",
        "        import os\n",
        "        print(\"\\n\ud83d\udcc1 Uploaded files:\")\n",
        "        for filename in os.listdir('.'):\n",
        "            if any(filename.startswith(prefix) for prefix in ['tabular_', 'sequences_', 'dataset_']):\n",
        "                print(f\"   {filename}\")\n",
        "                \n",
        "        return True\n",
        "        \n",
        "    except ImportError:\n",
        "        print(\"\u26a0\ufe0f Not running in Colab - skipping file upload\")\n",
        "        return False\n",
        "\n",
        "# Upload data (only in Colab)\n",
        "if 'google.colab' in globals():\n",
        "    upload_data_colab()\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f Not in Colab - please upload data files manually\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uac15\ud654\ub41c \ub370\uc774\ud130 \ub85c\ub529"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_data_robust"
      },
      "outputs": [],
      "source": [
        "def load_data_robust():",
        "    \"\"\"\uac15\ud654\ub41c \ub370\uc774\ud130 \ub85c\ub529 (\uc624\ub958 \ucc98\ub9ac \ud3ec\ud568)\"\"\"",
        "    ",
        "    import json",
        "    import glob",
        "    ",
        "    try:",
        "        # Find metadata file",
        "        metadata_files = glob.glob('dataset_metadata_*.json')",
        "        if not metadata_files:",
        "            raise FileNotFoundError(\"No metadata file found!\")",
        "        ",
        "        metadata_file = metadata_files[0]",
        "        with open(metadata_file, 'r') as f:",
        "            metadata = json.load(f)",
        "        ",
        "        timestamp = metadata['timestamp']",
        "        print(f\"\ud83d\udcca Loading datasets with timestamp: {timestamp}\")",
        "        ",
        "        # Load tabular data",
        "        train_df = pd.read_csv(f'tabular_train_{timestamp}.csv')",
        "        val_df = pd.read_csv(f'tabular_val_{timestamp}.csv')",
        "        test_df = pd.read_csv(f'tabular_test_{timestamp}.csv')",
        "        ",
        "        # Convert dates",
        "        train_df['date'] = pd.to_datetime(train_df['date'])",
        "        val_df['date'] = pd.to_datetime(val_df['date'])",
        "        test_df['date'] = pd.to_datetime(test_df['date'])",
        "        ",
        "        print(f\"\\n\ud83d\udcc8 Tabular data loaded successfully!\")",
        "        print(f\"   Train: {len(train_df)} samples\")",
        "        print(f\"   Validation: {len(val_df)} samples\")",
        "        print(f\"   Test: {len(test_df)} samples\")",
        "        print(f\"   Features: {len(metadata['tabular_features'])}\")",
        "        ",
        "        return train_df, val_df, test_df, metadata",
        "        ",
        "    except Exception as e:",
        "        print(f\"\u274c Error loading tabular data: {e}\")",
        "        raise",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uc2dc\ud000\uc2a4 \ub370\uc774\ud130 \uc900\ube44 (\ubb38\uc790\uc5f4 \uc624\ub958 \ud574\uacb0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prepare_sequence_data_fixed"
      },
      "outputs": [],
      "source": [
        "def prepare_sequence_data_fixed(metadata):",
        "    \"\"\"A100 GPU \ucd5c\uc801\ud654\ub41c \uc2dc\ud000\uc2a4 \ub370\uc774\ud130 \uc900\ube44 (\ubb38\uc790\uc5f4 \uc624\ub958 \ud574\uacb0)\"\"\"",
        "    ",
        "    try:",
        "        # Load sequence data",
        "        timestamp = metadata['timestamp']",
        "        sequences_data = np.load(f'sequences_{timestamp}.npz')",
        "        ",
        "        print(f\"\ud83d\udd0d Loading sequence data: {timestamp}\")",
        "        ",
        "        all_sequences = []",
        "        all_targets = []",
        "        all_dates = []",
        "        ",
        "        # \ub370\uc774\ud130 \ud0c0\uc785 \uac15\uc81c \ubcc0\ud658 \ubc0f \ubb38\uc790\uc5f4 \uc81c\uac70",
        "        for ticker in metadata['tickers']:",
        "            if f'{ticker}_sequences' in sequences_data:",
        "                sequences = sequences_data[f'{ticker}_sequences']",
        "                targets = sequences_data[f'{ticker}_targets_1d']",
        "                dates = sequences_data[f'{ticker}_dates']",
        "                ",
        "                print(f\"   Processing {ticker}: {sequences.shape}, dtype: {sequences.dtype}\")",
        "                ",
        "                # \ubb38\uc790\uc5f4\uc774 \ud3ec\ud568\ub41c \uacbd\uc6b0 \uc22b\uc790 \uceec\ub7fc\ub9cc \uc120\ud0dd",
        "                if sequences.dtype == object:",
        "                    print(f\"   \u26a0\ufe0f {ticker} has object dtype, cleaning...\")",
        "                    ",
        "                    numeric_cols = []",
        "                    for i in range(sequences.shape[2]):",
        "                        try:",
        "                            # \uac01 \uceec\ub7fc\uc744 float\ub85c \ubcc0\ud658 \uc2dc\ub3c4",
        "                            test_col = sequences[:, :, i].astype(float)",
        "                            numeric_cols.append(i)",
        "                        except:",
        "                            continue",
        "                    ",
        "                    if len(numeric_cols) > 0:",
        "                        sequences = sequences[:, :, numeric_cols].astype(np.float32)",
        "                        print(f\"   \u2705 {ticker}: {len(numeric_cols)} numeric columns extracted\")",
        "                    else:",
        "                        print(f\"   \u274c {ticker}: No numeric columns found, skipping\")",
        "                        continue",
        "                else:",
        "                    sequences = sequences.astype(np.float32)",
        "                ",
        "                # NaN \uac12 \ucc98\ub9ac",
        "                if np.any(np.isnan(sequences)) or np.any(np.isinf(sequences)):",
        "                    print(f\"   \ud83e\uddf9 {ticker}: Cleaning NaN/Inf values...\")",
        "                    sequences = np.nan_to_num(sequences, nan=0.0, posinf=0.0, neginf=0.0)",
        "                ",
        "                all_sequences.append(sequences)",
        "                all_targets.extend(targets)",
        "                all_dates.extend(dates)",
        "        ",
        "        if not all_sequences:",
        "            raise ValueError(\"\u274c No valid numeric sequences found!\")",
        "        ",
        "        # A100 \ucd5c\uc801\ud654: float32 \uc0ac\uc6a9",
        "        X_seq = np.vstack(all_sequences).astype(np.float32)",
        "        y_seq = np.array(all_targets, dtype=np.float32)",
        "        ",
        "        print(f\"\u2705 Sequence data prepared: {X_seq.shape}, dtype: {X_seq.dtype}\")",
        "        print(f\"   Total sequences: {len(all_sequences)}\")",
        "        print(f\"   Total targets: {len(y_seq)}\")",
        "        ",
        "        return X_seq, y_seq, all_dates",
        "        ",
        "    except Exception as e:",
        "        print(f\"\u274c Error preparing sequence data: {e}\")",
        "        print(\"\ud83d\udd27 Fallback to tabular models only...\")",
        "        return None, None, None",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uc2dc\ud000\uc2a4 \ucc28\uc6d0 \uac80\uc99d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "validate_sequence_dimensions"
      },
      "outputs": [],
      "source": [
        "def validate_sequence_dimensions(X_seq, y_seq):",
        "    \"\"\"\uc2dc\ud000\uc2a4 \ucc28\uc6d0 \uac80\uc99d\"\"\"",
        "    ",
        "    if X_seq is None or y_seq is None:",
        "        return False",
        "    ",
        "    print(f\"\ud83d\udd0d Sequence validation:\")",
        "    print(f\"   X shape: {X_seq.shape}\")",
        "    print(f\"   y shape: {y_seq.shape}\")",
        "    print(f\"   X dtype: {X_seq.dtype}\")",
        "    print(f\"   y dtype: {y_seq.dtype}\")",
        "    ",
        "    # \ucc28\uc6d0 \uac80\uc99d",
        "    if len(X_seq.shape) != 3:",
        "        print(f\"\u274c Expected 3D array, got {len(X_seq.shape)}D\")",
        "        return False",
        "    ",
        "    if X_seq.shape[0] != len(y_seq):",
        "        print(f\"\u274c Sample count mismatch: X={X_seq.shape[0]}, y={len(y_seq)}\")",
        "        return False",
        "    ",
        "    # NaN/Inf \uac80\uc0ac",
        "    if np.any(np.isnan(X_seq)) or np.any(np.isinf(X_seq)):",
        "        print(\"\u26a0\ufe0f Warning: NaN/Inf detected in sequences, cleaning...\")",
        "        X_seq = np.nan_to_num(X_seq, nan=0.0, posinf=0.0, neginf=0.0)",
        "    ",
        "    print(\"\u2705 Sequence validation passed!\")",
        "    return True",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uc2dc\ud000\uc2a4 \ub370\uc774\ud130 \ubd84\ud560"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_train_val_test_split"
      },
      "outputs": [],
      "source": [
        "def create_train_val_test_split(X_seq, y_seq, dates_seq):",
        "    \"\"\"\uc2dc\ud000\uc2a4 \ub370\uc774\ud130\ub97c \ud6c8\ub828/\uac80\uc99d/\ud14c\uc2a4\ud2b8\ub85c \ubd84\ud560\"\"\"",
        "    ",
        "    if X_seq is None:",
        "        return None, None, None, None, None, None",
        "    ",
        "    # \ub0a0\uc9dc \uae30\ubc18 \ubd84\ud560",
        "    dates_array = np.array([pd.to_datetime(d) for d in dates_seq])",
        "    ",
        "    train_end = pd.to_datetime('2023-02-02')",
        "    val_end = pd.to_datetime('2023-07-15')",
        "    ",
        "    train_mask = dates_array <= train_end",
        "    val_mask = (dates_array > train_end) & (dates_array <= val_end)",
        "    test_mask = dates_array > val_end",
        "    ",
        "    X_train_seq = X_seq[train_mask]",
        "    X_val_seq = X_seq[val_mask]",
        "    X_test_seq = X_seq[test_mask]",
        "    ",
        "    y_train_seq = y_seq[train_mask]",
        "    y_val_seq = y_seq[val_mask]",
        "    y_test_seq = y_seq[test_mask]",
        "    ",
        "    print(f\"\ud83d\udcca Sequence data split:\")",
        "    print(f\"   Train: {X_train_seq.shape}\")",
        "    print(f\"   Val: {X_val_seq.shape}\")",
        "    print(f\"   Test: {X_test_seq.shape}\")",
        "    ",
        "    return X_train_seq, X_val_seq, X_test_seq, y_train_seq, y_val_seq, y_test_seq",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud14c\uc774\ube14 \ub370\uc774\ud130 \uc900\ube44"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prepare_tabular_data"
      },
      "outputs": [],
      "source": [
        "def prepare_tabular_data(train_df, val_df, test_df, target='y1d'):",
        "    \"\"\"\ud14c\uc774\ube14 \ub370\uc774\ud130 \uc900\ube44\"\"\"",
        "    ",
        "    # Feature columns (exclude metadata and targets)",
        "    feature_cols = [col for col in train_df.columns ",
        "                   if col not in ['date', 'ticker', 'ticker_type', 'y1d', 'y5d', ",
        "                                 'alpha_1d', 'alpha_5d', 'direction_1d', 'direction_5d']]",
        "    ",
        "    # Prepare features and targets",
        "    X_train = train_df[feature_cols].fillna(0).values",
        "    X_val = val_df[feature_cols].fillna(0).values  ",
        "    X_test = test_df[feature_cols].fillna(0).values",
        "    ",
        "    y_train = train_df[target].values",
        "    y_val = val_df[target].values",
        "    y_test = test_df[target].values",
        "    ",
        "    # Scale features",
        "    scaler = RobustScaler()  # More robust to outliers",
        "    X_train_scaled = scaler.fit_transform(X_train)",
        "    X_val_scaled = scaler.transform(X_val)",
        "    X_test_scaled = scaler.transform(X_test)",
        "    ",
        "    return (X_train_scaled, X_val_scaled, X_test_scaled, ",
        "            y_train, y_val, y_test, feature_cols, scaler)",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## IC \uba54\ud2b8\ub9ad \uacc4\uc0b0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "calculate_ic_metrics"
      },
      "outputs": [],
      "source": [
        "def calculate_ic_metrics(y_true, y_pred):",
        "    \"\"\"Information Coefficient \uba54\ud2b8\ub9ad \uacc4\uc0b0\"\"\"",
        "    ",
        "    # Remove NaN values",
        "    mask = np.isfinite(y_true) & np.isfinite(y_pred)",
        "    if mask.sum() == 0:",
        "        return {'ic': 0, 'rank_ic': 0, 'hit_rate': 0.5}",
        "    ",
        "    y_true_clean = y_true[mask]",
        "    y_pred_clean = y_pred[mask]",
        "    ",
        "    # Calculate correlations",
        "    ic, ic_p = pearsonr(y_pred_clean, y_true_clean) if len(y_true_clean) > 2 else (0, 1)",
        "    rank_ic, rank_p = spearmanr(y_pred_clean, y_true_clean)",
        "    ",
        "    # Hit rate (directional accuracy)",
        "    hit_rate = np.mean(np.sign(y_pred_clean) == np.sign(y_true_clean))",
        "    ",
        "    return {",
        "        'ic': ic if not np.isnan(ic) else 0,",
        "        'rank_ic': rank_ic if not np.isnan(rank_ic) else 0,",
        "        'ic_p_value': ic_p,",
        "        'rank_ic_p_value': rank_p,",
        "        'hit_rate': hit_rate,",
        "        'n_samples': len(y_true_clean)",
        "    }",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ubaa8\ub378 \ud3c9\uac00"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evaluate_model"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_test, y_test, model_name, device):",
        "    \"\"\"\ubaa8\ub378 \ud3c9\uac00\"\"\"",
        "    ",
        "    if hasattr(model, 'predict'):",
        "        y_pred = model.predict(X_test)",
        "    else:",
        "        # PyTorch model",
        "        model.eval()",
        "        with torch.no_grad():",
        "            X_tensor = torch.FloatTensor(X_test).to(device)",
        "            y_pred = model(X_tensor).cpu().numpy().flatten()",
        "    ",
        "    # Calculate metrics",
        "    ic_metrics = calculate_ic_metrics(y_test, y_pred)",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))",
        "    ",
        "    results = {",
        "        'model': model_name,",
        "        'rmse': rmse,",
        "        **ic_metrics",
        "    }",
        "    ",
        "    return results, y_pred",
        "",
        "# A100 \ucd5c\uc801\ud654\ub41c \ubaa8\ub378 \ud074\ub798\uc2a4\ub4e4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A100 \ucd5c\uc801\ud654\ub41c Deep MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeepMLP"
      },
      "outputs": [],
      "source": [
        "class DeepMLP(nn.Module):",
        "    \"\"\"A100 GPU \ucd5c\uc801\ud654\ub41c Deep MLP\"\"\"",
        "    ",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A100 \ucd5c\uc801\ud654\ub41c LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSTMModel"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):",
        "    \"\"\"A100 GPU \ucd5c\uc801\ud654\ub41c LSTM\"\"\"",
        "    ",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A100 GPU \ucd5c\uc801\ud654\ub41c MLP \ud6c8\ub828"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_mlp_a100"
      },
      "outputs": [],
      "source": [
        "def train_mlp_a100(X_train, y_train, X_val, y_val, device, epochs=300, lr=0.001):",
        "    \"\"\"A100 GPU \ucd5c\uc801\ud654\ub41c MLP \ud6c8\ub828\"\"\"",
        "    ",
        "    model = DeepMLP(X_train.shape[1]).to(device)",
        "    criterion = nn.MSELoss()",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=20, factor=0.5)",
        "    ",
        "    # A100 \ucd5c\uc801\ud654: \ud63c\ud569 \uc815\ubc00\ub3c4 \ud6c8\ub828",
        "    scaler = GradScaler()",
        "    ",
        "    # Convert to tensors",
        "    X_train_tensor = torch.FloatTensor(X_train).to(device)",
        "    y_train_tensor = torch.FloatTensor(y_train).to(device)",
        "    X_val_tensor = torch.FloatTensor(X_val).to(device)",
        "    y_val_tensor = torch.FloatTensor(y_val).to(device)",
        "    ",
        "    train_losses = []",
        "    val_losses = []",
        "    val_ics = []",
        "    ",
        "    best_ic = -float('inf')",
        "    best_model = None",
        "    patience_counter = 0",
        "    ",
        "    print(\"\ud83e\udde0 Training MLP with A100 optimization...\")",
        "    ",
        "    for epoch in range(epochs):",
        "        # Training with mixed precision",
        "        model.train()",
        "        optimizer.zero_grad()",
        "        ",
        "        with autocast():",
        "            outputs = model(X_train_tensor).squeeze()",
        "            train_loss = criterion(outputs, y_train_tensor)",
        "        ",
        "        scaler.scale(train_loss).backward()",
        "        scaler.step(optimizer)",
        "        scaler.update()",
        "        ",
        "        # Validation",
        "        model.eval()",
        "        with torch.no_grad():",
        "            val_outputs = model(X_val_tensor).squeeze()",
        "            val_loss = criterion(val_outputs, y_val_tensor)",
        "            ",
        "            # Calculate IC",
        "            val_pred_np = val_outputs.cpu().numpy()",
        "            val_ic_metrics = calculate_ic_metrics(y_val, val_pred_np)",
        "            val_ic = val_ic_metrics['rank_ic']",
        "        ",
        "        train_losses.append(train_loss.item())",
        "        val_losses.append(val_loss.item())",
        "        val_ics.append(val_ic)",
        "        ",
        "        scheduler.step(val_loss)",
        "        ",
        "        # Early stopping based on IC",
        "        if val_ic > best_ic:",
        "            best_ic = val_ic",
        "            best_model = model.state_dict().copy()",
        "            patience_counter = 0",
        "        else:",
        "            patience_counter += 1",
        "        ",
        "        if epoch % 50 == 0:",
        "            print(f\"Epoch {epoch}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val IC: {val_ic:.4f}\")",
        "        ",
        "        if patience_counter >= 40:  # Early stopping",
        "            print(f\"Early stopping at epoch {epoch}\")",
        "            break",
        "    ",
        "    # Load best model",
        "    model.load_state_dict(best_model)",
        "    ",
        "    return model, train_losses, val_losses, val_ics",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A100 GPU \ucd5c\uc801\ud654\ub41c LSTM \ud6c8\ub828"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_lstm_a100"
      },
      "outputs": [],
      "source": [
        "def train_lstm_a100(X_train, y_train, X_val, y_val, device, epochs=150, batch_size=256, lr=0.001):",
        "    \"\"\"A100 GPU \ucd5c\uc801\ud654\ub41c LSTM \ud6c8\ub828\"\"\"",
        "    ",
        "    input_size = X_train.shape[2]",
        "    model = LSTMModel(input_size).to(device)",
        "    criterion = nn.MSELoss()",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)",
        "    ",
        "    # A100 \ucd5c\uc801\ud654: \ud63c\ud569 \uc815\ubc00\ub3c4 \ud6c8\ub828",
        "    scaler = GradScaler()",
        "    ",
        "    # Create data loaders with larger batch size",
        "    train_dataset = TensorDataset(",
        "        torch.FloatTensor(X_train),",
        "        torch.FloatTensor(y_train)",
        "    )",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)",
        "    ",
        "    val_dataset = TensorDataset(",
        "        torch.FloatTensor(X_val),",
        "        torch.FloatTensor(y_val)",
        "    )",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)",
        "    ",
        "    train_losses = []",
        "    val_ics = []",
        "    best_ic = -float('inf')",
        "    best_model = None",
        "    ",
        "    print(f\"\ud83d\udd04 Training LSTM with A100 optimization (batch_size={batch_size})...\")",
        "    ",
        "    for epoch in range(epochs):",
        "        # Training with mixed precision",
        "        model.train()",
        "        train_loss = 0",
        "        ",
        "        for batch_X, batch_y in train_loader:",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)",
        "            ",
        "            optimizer.zero_grad()",
        "            ",
        "            with autocast():",
        "                outputs = model(batch_X).squeeze()",
        "                loss = criterion(outputs, batch_y)",
        "            ",
        "            scaler.scale(loss).backward()",
        "            ",
        "            # Gradient clipping",
        "            scaler.unscale_(optimizer)",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)",
        "            ",
        "            scaler.step(optimizer)",
        "            scaler.update()",
        "            ",
        "            train_loss += loss.item()",
        "        ",
        "        # Validation",
        "        model.eval()",
        "        val_predictions = []",
        "        val_actuals = []",
        "        ",
        "        with torch.no_grad():",
        "            for batch_X, batch_y in val_loader:",
        "                batch_X = batch_X.to(device)",
        "                outputs = model(batch_X).squeeze()",
        "                ",
        "                val_predictions.extend(outputs.cpu().numpy())",
        "                val_actuals.extend(batch_y.numpy())",
        "        ",
        "        val_ic_metrics = calculate_ic_metrics(np.array(val_actuals), np.array(val_predictions))",
        "        val_ic = val_ic_metrics['rank_ic']",
        "        ",
        "        train_losses.append(train_loss / len(train_loader))",
        "        val_ics.append(val_ic)",
        "        ",
        "        if val_ic > best_ic:",
        "            best_ic = val_ic",
        "            best_model = model.state_dict().copy()",
        "        ",
        "        if epoch % 20 == 0:",
        "            print(f\"Epoch {epoch}: Train Loss: {train_loss/len(train_loader):.4f}, Val IC: {val_ic:.4f}\")",
        "    ",
        "    # Load best model",
        "    model.load_state_dict(best_model)",
        "    return model, train_losses, val_ics",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uba54\uc778 \uc2e4\ud589 \ud568\uc218"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "main"
      },
      "outputs": [],
      "source": [
        "def main():",
        "    \"\"\"\uba54\uc778 \uc2e4\ud589 \ud568\uc218\"\"\"",
        "    ",
        "    print(\"\ud83d\ude80 Starting Meme Stock Deep Learning (A100 GPU Optimized)\")",
        "    ",
        "    # 1. A100 GPU \ucd5c\uc801\ud654 \uc124\uc815",
        "    device = setup_a100_optimization()",
        "    ",
        "    # 2. \ud328\ud0a4\uc9c0 \uc124\uce58 (Colab\uc5d0\uc11c\ub9cc)",
        "    if 'google.colab' in sys.modules:",
        "        install_packages()",
        "    ",
        "    # 3. \ub370\uc774\ud130 \uc5c5\ub85c\ub4dc (Colab\uc5d0\uc11c\ub9cc)",
        "    if 'google.colab' in sys.modules:",
        "        upload_data_colab()",
        "    ",
        "    # 4. \ub370\uc774\ud130 \ub85c\ub529",
        "    try:",
        "        train_df, val_df, test_df, metadata = load_data_robust()",
        "        print(\"\u2705 Tabular data loaded successfully\")",
        "    except Exception as e:",
        "        print(f\"\u274c Failed to load tabular data: {e}\")",
        "        return",
        "    ",
        "    # 5. \uc2dc\ud000\uc2a4 \ub370\uc774\ud130 \uc900\ube44 (\uc624\ub958 \ucc98\ub9ac \ud3ec\ud568)",
        "    try:",
        "        X_seq, y_seq, dates_seq = prepare_sequence_data_fixed(metadata)",
        "        ",
        "        if X_seq is not None:",
        "            # \ucc28\uc6d0 \uac80\uc99d",
        "            if validate_sequence_dimensions(X_seq, y_seq):",
        "                # \ub370\uc774\ud130 \ubd84\ud560",
        "                X_train_seq, X_val_seq, X_test_seq, y_train_seq, y_val_seq, y_test_seq = create_train_val_test_split(",
        "                    X_seq, y_seq, dates_seq",
        "                )",
        "                USE_SEQUENCE_MODELS = True",
        "                print(\"\u2705 Sequence models enabled\")",
        "            else:",
        "                USE_SEQUENCE_MODELS = False",
        "                print(\"\u26a0\ufe0f Sequence models disabled due to validation failure\")",
        "        else:",
        "            USE_SEQUENCE_MODELS = False",
        "            print(\"\u26a0\ufe0f Sequence models disabled - no sequence data\")",
        "            ",
        "    except Exception as e:",
        "        print(f\"\u26a0\ufe0f Sequence data preparation failed: {e}\")",
        "        USE_SEQUENCE_MODELS = False",
        "        print(\"\u26a0\ufe0f Sequence models disabled\")",
        "    ",
        "    # 6. \ud14c\uc774\ube14 \ub370\uc774\ud130 \uc900\ube44",
        "    X_train, X_val, X_test, y_train, y_val, y_test, feature_cols, scaler = prepare_tabular_data(",
        "        train_df, val_df, test_df, target='y1d'",
        "    )",
        "    ",
        "    print(f\"\ud83d\udcca Tabular data prepared: {X_train.shape[1]} features\")",
        "    ",
        "    # 7. \ubaa8\ub378 \ud6c8\ub828 \ubc0f \ud3c9\uac00",
        "    results = []",
        "    ",
        "    # MLP \ubaa8\ub378",
        "    try:",
        "        print(\"\\n\ud83e\udde0 Training MLP...\")",
        "        mlp_model, mlp_train_losses, mlp_val_losses, mlp_val_ics = train_mlp_a100(",
        "            X_train, y_train, X_val, y_val, device",
        "        )",
        "        ",
        "        mlp_results, mlp_predictions = evaluate_model(mlp_model, X_test, y_test, 'MLP', device)",
        "        results.append(mlp_results)",
        "        ",
        "        print(f\"\u2705 MLP Results: IC={mlp_results['ic']:.4f}, Rank IC={mlp_results['rank_ic']:.4f}\")",
        "        ",
        "    except Exception as e:",
        "        print(f\"\u274c MLP training failed: {e}\")",
        "    ",
        "    # LSTM \ubaa8\ub378 (\uc2dc\ud000\uc2a4 \ub370\uc774\ud130\uac00 \uc788\ub294 \uacbd\uc6b0)",
        "    if USE_SEQUENCE_MODELS and X_train_seq is not None:",
        "        try:",
        "            print(\"\\n\ud83d\udd04 Training LSTM...\")",
        "            lstm_model, lstm_train_losses, lstm_val_ics = train_lstm_a100(",
        "                X_train_seq, y_train_seq, X_val_seq, y_val_seq, device",
        "            )",
        "            ",
        "            # LSTM \ud3c9\uac00",
        "            lstm_model.eval()",
        "            with torch.no_grad():",
        "                X_test_tensor = torch.FloatTensor(X_test_seq).to(device)",
        "                lstm_predictions = lstm_model(X_test_tensor).cpu().numpy().flatten()",
        "            ",
        "            lstm_results = calculate_ic_metrics(y_test_seq, lstm_predictions)",
        "            lstm_results['model'] = 'LSTM'",
        "            lstm_results['rmse'] = np.sqrt(mean_squared_error(y_test_seq, lstm_predictions))",
        "            ",
        "            results.append(lstm_results)",
        "            print(f\"\u2705 LSTM Results: IC={lstm_results['ic']:.4f}, Rank IC={lstm_results['rank_ic']:.4f}\")",
        "            ",
        "        except Exception as e:",
        "            print(f\"\u274c LSTM training failed: {e}\")",
        "    ",
        "    # 8. \uacb0\uacfc \uc694\uc57d",
        "    if results:",
        "        print(f\"\\n\ud83c\udfc6 FINAL RESULTS SUMMARY\")",
        "        print(\"=\" * 50)",
        "        ",
        "        for result in results:",
        "            print(f\"{result['model']}: IC={result['ic']:.4f}, Rank IC={result['rank_ic']:.4f}, Hit Rate={result['hit_rate']:.3%}\")",
        "        ",
        "        # \ucd5c\uace0 \uc131\ub2a5 \ubaa8\ub378 \ucc3e\uae30",
        "        best_result = max(results, key=lambda x: x['rank_ic'])",
        "        print(f\"\\n\ud83e\udd47 BEST MODEL: {best_result['model']}\")",
        "        print(f\"   Rank IC: {best_result['rank_ic']:.4f}\")",
        "        print(f\"   Hit Rate: {best_result['hit_rate']:.3%}\")",
        "        ",
        "        # Go/No-Go \ud310\uc815",
        "        ic_improvement = best_result['rank_ic'] - 0.0  # Random walk baseline",
        "        meets_threshold = ic_improvement >= 0.03 and best_result['hit_rate'] > 0.55",
        "        ",
        "        if meets_threshold:",
        "            print(f\"\\n\ud83d\ude80 GO DECISION: Model meets success criteria!\")",
        "        else:",
        "            print(f\"\\n\ud83d\udd04 CONTINUE: Model close to threshold but needs improvement\")",
        "            ",
        "    else:",
        "        print(\"\u274c No models trained successfully\")",
        "    ",
        "    print(\"\\n\u2705 Deep Learning pipeline completed!\")",
        "",
        "if __name__ == \"__main__\":",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}