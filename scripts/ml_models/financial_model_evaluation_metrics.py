#!/usr/bin/env python3
"""
Financial Model Evaluation Metrics
=================================
ê¸ˆìœµ ì˜ˆì¸¡ ëª¨ë¸ì„ ìœ„í•œ ì „ë¬¸ í‰ê°€ ì§€í‘œë“¤

ì¼ë°˜ MLê³¼ ë‹¤ë¥¸ ê¸ˆìœµ íŠ¹í™” ì§€í‘œë“¤:
1. Information Coefficient (IC) - ì˜ˆì¸¡ë ¥ ì¸¡ì •
2. Information Ratio (IR) - ìœ„í—˜ ëŒ€ë¹„ ìˆ˜ìµ
3. Hit Rate - ë°©í–¥ì„± ì •í™•ë„  
4. Sharpe Ratio - ìœ„í—˜ ì¡°ì • ìˆ˜ìµë¥ 
5. Maximum Drawdown - ìµœëŒ€ ì†ì‹¤
6. Calmar Ratio - ìœ„í—˜ ëŒ€ë¹„ ì„±ê³¼
"""

import pandas as pd
import numpy as np
from scipy.stats import pearsonr, spearmanr
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple
import warnings
warnings.filterwarnings('ignore')

class FinancialModelEvaluator:
    """ê¸ˆìœµ ëª¨ë¸ ì „ìš© í‰ê°€ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.metrics = {}
        
    def calculate_information_coefficient(self, y_true: np.ndarray, y_pred: np.ndarray) -> Dict:
        """
        Information Coefficient (IC) - ê¸ˆìœµì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ì§€í‘œ
        
        IC = Correlation(ì‹¤ì œìˆ˜ìµë¥ , ì˜ˆì¸¡ìˆ˜ìµë¥ )
        - IC > 0.05: ë§¤ìš° ì¢‹ìŒ
        - IC > 0.03: ì¢‹ìŒ  
        - IC > 0.01: ë³´í†µ
        - IC < 0: ì—­ë°©í–¥ (contrarian ì‹ í˜¸)
        """
        # Pearson IC (ì„ í˜• ê´€ê³„)
        ic_pearson, ic_p_value = pearsonr(y_true, y_pred)
        
        # Rank IC (ë¹„ì„ í˜• ê´€ê³„, Spearman)
        ic_rank, rank_p_value = spearmanr(y_true, y_pred)
        
        # IC í†µê³„ëŸ‰
        ic_mean = ic_pearson
        ic_std = np.std([ic_pearson])  # ì‹¤ì œë¡œëŠ” rolling windowë¡œ ê³„ì‚°
        
        # Information Ratio = IC / IC_std
        information_ratio = ic_mean / (ic_std + 1e-8)
        
        return {
            'ic_pearson': ic_pearson,
            'ic_rank': ic_rank,
            'ic_p_value': ic_p_value,
            'rank_p_value': rank_p_value,
            'information_ratio': information_ratio,
            'ic_significance': 'Significant' if ic_p_value < 0.05 else 'Not Significant'
        }
    
    def calculate_hit_rate(self, y_true: np.ndarray, y_pred: np.ndarray) -> Dict:
        """
        Hit Rate - ë°©í–¥ì„± ì˜ˆì¸¡ ì •í™•ë„
        
        ì¼ë°˜ ML accuracyì™€ ë‹¤ë¦„:
        - ë‹¨ìˆœíˆ ë§ì¶˜ ê°œìˆ˜ê°€ ì•„ë‹ˆë¼ 'ë°©í–¥'ì„ ë§ì¶˜ ë¹„ìœ¨
        - ê¸ˆìœµì—ì„œëŠ” í¬ê¸°ë³´ë‹¤ ë°©í–¥ì´ ë” ì¤‘ìš”í•  ë•Œê°€ ë§ìŒ
        """
        # ë°©í–¥ì„± ê³„ì‚°
        actual_direction = np.sign(y_true)
        predicted_direction = np.sign(y_pred)
        
        # Hit rate ê³„ì‚°
        hit_rate = np.mean(actual_direction == predicted_direction)
        
        # ì„¸ë¶„í™”ëœ hit rate
        positive_mask = y_true > 0
        negative_mask = y_true < 0
        
        hit_rate_positive = np.mean(actual_direction[positive_mask] == predicted_direction[positive_mask]) if np.any(positive_mask) else 0
        hit_rate_negative = np.mean(actual_direction[negative_mask] == predicted_direction[negative_mask]) if np.any(negative_mask) else 0
        
        return {
            'overall_hit_rate': hit_rate,
            'hit_rate_up_days': hit_rate_positive,
            'hit_rate_down_days': hit_rate_negative,
            'up_day_count': np.sum(positive_mask),
            'down_day_count': np.sum(negative_mask)
        }
    
    def calculate_financial_returns_metrics(self, y_true: np.ndarray, y_pred: np.ndarray) -> Dict:
        """
        ê¸ˆìœµ ìˆ˜ìµë¥  ê¸°ë°˜ ì§€í‘œë“¤
        
        ì‹¤ì œ ê±°ë˜í–ˆì„ ë•Œì˜ ì„±ê³¼ë¥¼ ì‹œë®¬ë ˆì´ì…˜
        """
        # ì˜ˆì¸¡ ê¸°ë°˜ í¬ì§€ì…˜ ìƒì„± (1: ë§¤ìˆ˜, -1: ë§¤ë„, 0: ì¤‘ë¦½)
        positions = np.sign(y_pred)
        
        # ì‹¤ì œ ìˆ˜ìµë¥ ê³¼ í¬ì§€ì…˜ìœ¼ë¡œ ì „ëµ ìˆ˜ìµë¥  ê³„ì‚°
        strategy_returns = positions * y_true
        
        # ë²¤ì¹˜ë§ˆí¬ (ë‹¨ìˆœ ë§¤ìˆ˜ ë³´ìœ )
        benchmark_returns = y_true
        
        # ëˆ„ì  ìˆ˜ìµë¥ 
        cumulative_strategy = np.cumprod(1 + strategy_returns) - 1
        cumulative_benchmark = np.cumprod(1 + benchmark_returns) - 1
        
        # ì—°ê°„í™” (252 ê±°ë˜ì¼ ê¸°ì¤€)
        trading_days = 252
        n_periods = len(strategy_returns)
        
        # Sharpe Ratio
        strategy_sharpe = np.mean(strategy_returns) / (np.std(strategy_returns) + 1e-8) * np.sqrt(trading_days)
        benchmark_sharpe = np.mean(benchmark_returns) / (np.std(benchmark_returns) + 1e-8) * np.sqrt(trading_days)
        
        # Maximum Drawdown
        def calculate_max_drawdown(returns):
            cumulative = np.cumprod(1 + returns)
            running_max = np.maximum.accumulate(cumulative)
            drawdown = (cumulative - running_max) / running_max
            return np.min(drawdown)
        
        strategy_max_dd = calculate_max_drawdown(strategy_returns)
        benchmark_max_dd = calculate_max_drawdown(benchmark_returns)
        
        # Calmar Ratio = Annual Return / |Max Drawdown|
        annual_strategy_return = np.mean(strategy_returns) * trading_days
        annual_benchmark_return = np.mean(benchmark_returns) * trading_days
        
        strategy_calmar = annual_strategy_return / (abs(strategy_max_dd) + 1e-8)
        benchmark_calmar = annual_benchmark_return / (abs(benchmark_max_dd) + 1e-8)
        
        return {
            'strategy_total_return': cumulative_strategy[-1],
            'benchmark_total_return': cumulative_benchmark[-1],
            'strategy_annual_return': annual_strategy_return,
            'benchmark_annual_return': annual_benchmark_return,
            'strategy_sharpe': strategy_sharpe,
            'benchmark_sharpe': benchmark_sharpe,
            'strategy_max_drawdown': strategy_max_dd,
            'benchmark_max_drawdown': benchmark_max_dd,
            'strategy_calmar': strategy_calmar,
            'benchmark_calmar': benchmark_calmar,
            'excess_return': annual_strategy_return - annual_benchmark_return
        }
    
    def calculate_volatility_metrics(self, y_true: np.ndarray, y_pred: np.ndarray) -> Dict:
        """
        ë³€ë™ì„± ê´€ë ¨ ì§€í‘œë“¤
        
        ë°ˆìŠ¤í†¡ì€ ë³€ë™ì„±ì´ ë§¤ìš° ë†’ìœ¼ë¯€ë¡œ ì¤‘ìš”
        """
        # ì˜ˆì¸¡ ì˜¤ì°¨
        errors = y_pred - y_true
        
        # ë³€ë™ì„± ì˜ˆì¸¡ ì •í™•ë„
        actual_vol = np.std(y_true)
        predicted_vol = np.std(y_pred)
        
        # ì¡°ê±´ë¶€ ë³€ë™ì„± (ìƒìŠ¹/í•˜ë½ì¥ì—ì„œì˜ ì˜ˆì¸¡ ì •í™•ë„)
        up_days = y_true > 0
        down_days = y_true < 0
        
        up_day_accuracy = np.mean(np.abs(errors[up_days])) if np.any(up_days) else 0
        down_day_accuracy = np.mean(np.abs(errors[down_days])) if np.any(down_days) else 0
        
        return {
            'actual_volatility': actual_vol,
            'predicted_volatility': predicted_vol,
            'volatility_ratio': predicted_vol / (actual_vol + 1e-8),
            'error_volatility': np.std(errors),
            'up_day_mae': up_day_accuracy,
            'down_day_mae': down_day_accuracy,
            'vol_timing_ability': 1 - (up_day_accuracy + down_day_accuracy) / (2 * np.mean(np.abs(errors)))
        }
    
    def calculate_regime_based_metrics(self, y_true: np.ndarray, y_pred: np.ndarray) -> Dict:
        """
        ì‹œì¥ ìƒí™©ë³„ ì„±ê³¼ ì§€í‘œ
        
        ë°ˆìŠ¤í†¡ì€ viral/normal êµ¬ê°„ì´ ë‹¤ë¥´ë¯€ë¡œ ì¤‘ìš”
        """
        # ë³€ë™ì„± ê¸°ì¤€ìœ¼ë¡œ regime êµ¬ë¶„
        vol_threshold = np.percentile(np.abs(y_true), 75)  # ìƒìœ„ 25%ë¥¼ ê³ ë³€ë™ì„±ìœ¼ë¡œ ì •ì˜
        
        high_vol_mask = np.abs(y_true) > vol_threshold
        low_vol_mask = ~high_vol_mask
        
        # ê° regimeì—ì„œì˜ ì„±ê³¼
        def regime_metrics(mask, regime_name):
            if not np.any(mask):
                return {}
            
            regime_true = y_true[mask]
            regime_pred = y_pred[mask]
            
            ic, _ = pearsonr(regime_true, regime_pred)
            hit_rate = np.mean(np.sign(regime_true) == np.sign(regime_pred))
            
            return {
                f'{regime_name}_ic': ic,
                f'{regime_name}_hit_rate': hit_rate,
                f'{regime_name}_samples': np.sum(mask),
                f'{regime_name}_mae': np.mean(np.abs(regime_pred - regime_true))
            }
        
        high_vol_metrics = regime_metrics(high_vol_mask, 'high_vol')
        low_vol_metrics = regime_metrics(low_vol_mask, 'low_vol')
        
        return {**high_vol_metrics, **low_vol_metrics}
    
    def calculate_traditional_ml_metrics(self, y_true: np.ndarray, y_pred: np.ndarray) -> Dict:
        """
        ì „í†µì ì¸ ML ì§€í‘œë“¤ (ì°¸ê³ ìš©)
        """
        return {
            'mse': mean_squared_error(y_true, y_pred),
            'mae': mean_absolute_error(y_true, y_pred),
            'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),
            'r2': r2_score(y_true, y_pred),
            'explained_variance': 1 - np.var(y_true - y_pred) / np.var(y_true)
        }
    
    def comprehensive_evaluation(self, y_true: np.ndarray, y_pred: np.ndarray, 
                               model_name: str = "Model") -> Dict:
        """
        ì¢…í•©ì ì¸ ê¸ˆìœµ ëª¨ë¸ í‰ê°€
        """
        print(f"ğŸ“Š Comprehensive Financial Model Evaluation: {model_name}")
        print("=" * 60)
        
        # 1. Information Coefficient
        ic_metrics = self.calculate_information_coefficient(y_true, y_pred)
        print(f"\nğŸ“ˆ INFORMATION COEFFICIENT:")
        print(f"   IC (Pearson): {ic_metrics['ic_pearson']:.4f}")
        print(f"   IC (Rank): {ic_metrics['ic_rank']:.4f}")
        print(f"   Information Ratio: {ic_metrics['information_ratio']:.4f}")
        print(f"   Significance: {ic_metrics['ic_significance']}")
        
        # 2. Hit Rate
        hit_metrics = self.calculate_hit_rate(y_true, y_pred)
        print(f"\nğŸ¯ HIT RATE ANALYSIS:")
        print(f"   Overall Hit Rate: {hit_metrics['overall_hit_rate']:.1%}")
        print(f"   Up Days Hit Rate: {hit_metrics['hit_rate_up_days']:.1%}")
        print(f"   Down Days Hit Rate: {hit_metrics['hit_rate_down_days']:.1%}")
        
        # 3. Financial Returns
        returns_metrics = self.calculate_financial_returns_metrics(y_true, y_pred)
        print(f"\nğŸ’° FINANCIAL PERFORMANCE:")
        print(f"   Strategy Return: {returns_metrics['strategy_total_return']:.1%}")
        print(f"   Benchmark Return: {returns_metrics['benchmark_total_return']:.1%}")
        print(f"   Excess Return: {returns_metrics['excess_return']:.1%}")
        print(f"   Strategy Sharpe: {returns_metrics['strategy_sharpe']:.2f}")
        print(f"   Max Drawdown: {returns_metrics['strategy_max_drawdown']:.1%}")
        
        # 4. Volatility Analysis
        vol_metrics = self.calculate_volatility_metrics(y_true, y_pred)
        print(f"\nğŸ“Š VOLATILITY ANALYSIS:")
        print(f"   Actual Vol: {vol_metrics['actual_volatility']:.1%}")
        print(f"   Predicted Vol: {vol_metrics['predicted_volatility']:.1%}")
        print(f"   Vol Timing Ability: {vol_metrics['vol_timing_ability']:.2f}")
        
        # 5. Regime Analysis
        regime_metrics = self.calculate_regime_based_metrics(y_true, y_pred)
        print(f"\nğŸŒªï¸ REGIME ANALYSIS:")
        if 'high_vol_ic' in regime_metrics:
            print(f"   High Vol IC: {regime_metrics['high_vol_ic']:.4f}")
            print(f"   High Vol Hit Rate: {regime_metrics['high_vol_hit_rate']:.1%}")
        if 'low_vol_ic' in regime_metrics:
            print(f"   Low Vol IC: {regime_metrics['low_vol_ic']:.4f}")
            print(f"   Low Vol Hit Rate: {regime_metrics['low_vol_hit_rate']:.1%}")
        
        # 6. Traditional ML (ì°¸ê³ ìš©)
        ml_metrics = self.calculate_traditional_ml_metrics(y_true, y_pred)
        print(f"\nğŸ¤– TRADITIONAL ML METRICS (Reference):")
        print(f"   RÂ²: {ml_metrics['r2']:.4f}")
        print(f"   RMSE: {ml_metrics['rmse']:.4f}")
        print(f"   MAE: {ml_metrics['mae']:.4f}")
        
        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        overall_score = self._calculate_overall_score(ic_metrics, hit_metrics, returns_metrics)
        print(f"\nğŸ† OVERALL SCORE: {overall_score:.2f}/100")
        
        # ëª¨ë“  ì§€í‘œ í†µí•©
        all_metrics = {
            'model_name': model_name,
            'overall_score': overall_score,
            **ic_metrics,
            **hit_metrics,
            **returns_metrics,
            **vol_metrics,
            **regime_metrics,
            **ml_metrics
        }
        
        return all_metrics
    
    def _calculate_overall_score(self, ic_metrics: Dict, hit_metrics: Dict, 
                                returns_metrics: Dict) -> float:
        """
        ì¢…í•© ì ìˆ˜ ê³„ì‚° (0-100)
        
        ê°€ì¤‘ì¹˜:
        - IC: 40%
        - Hit Rate: 30%  
        - Returns: 30%
        """
        # IC ì ìˆ˜ (0-40)
        ic_score = min(40, abs(ic_metrics['ic_pearson']) * 1000)  # 0.04 IC = 40ì 
        
        # Hit Rate ì ìˆ˜ (0-30)
        hit_rate = hit_metrics['overall_hit_rate']
        hit_score = max(0, (hit_rate - 0.5) * 60)  # 50% = 0ì , 100% = 30ì 
        
        # Returns ì ìˆ˜ (0-30)
        sharpe = returns_metrics['strategy_sharpe']
        returns_score = min(30, max(0, sharpe * 15))  # Sharpe 2.0 = 30ì 
        
        return ic_score + hit_score + returns_score
    
    def model_comparison_report(self, results: List[Dict]):
        """
        ì—¬ëŸ¬ ëª¨ë¸ ë¹„êµ ë¦¬í¬íŠ¸
        """
        print("\n" + "="*80)
        print("ğŸ“Š MULTI-MODEL COMPARISON REPORT")
        print("="*80)
        
        # ì •ë ¬ ê¸°ì¤€ë³„ ë­í‚¹
        rankings = {
            'overall_score': sorted(results, key=lambda x: x['overall_score'], reverse=True),
            'ic_pearson': sorted(results, key=lambda x: abs(x['ic_pearson']), reverse=True),
            'overall_hit_rate': sorted(results, key=lambda x: x['overall_hit_rate'], reverse=True),
            'strategy_sharpe': sorted(results, key=lambda x: x['strategy_sharpe'], reverse=True)
        }
        
        print(f"\nğŸ† RANKINGS BY DIFFERENT CRITERIA:")
        print(f"{'Rank':<4} {'Overall':<15} {'IC Leader':<15} {'Hit Rate':<15} {'Sharpe':<15}")
        print("-" * 70)
        
        for i in range(min(5, len(results))):
            print(f"{i+1:<4} "
                  f"{rankings['overall_score'][i]['model_name']:<15} "
                  f"{rankings['ic_pearson'][i]['model_name']:<15} "
                  f"{rankings['overall_hit_rate'][i]['model_name']:<15} "
                  f"{rankings['strategy_sharpe'][i]['model_name']:<15}")
        
        # ìµœê³  ì„±ê³¼ ëª¨ë¸
        best_model = rankings['overall_score'][0]
        print(f"\nğŸ¥‡ BEST OVERALL MODEL: {best_model['model_name']}")
        print(f"   Overall Score: {best_model['overall_score']:.1f}/100")
        print(f"   IC: {best_model['ic_pearson']:.4f}")
        print(f"   Hit Rate: {best_model['overall_hit_rate']:.1%}")
        print(f"   Sharpe: {best_model['strategy_sharpe']:.2f}")
        
        return best_model


def demo_evaluation():
    """
    í‰ê°€ ì§€í‘œ ë°ëª¨
    """
    print("ğŸ“Š Financial Model Evaluation Metrics Demo")
    print("="*50)
    
    # ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ì‹¤ì œ ë°ˆìŠ¤í†¡ íŒ¨í„´ ëª¨ë°©)
    np.random.seed(42)
    n_samples = 100
    
    # ì‹¤ì œ ìˆ˜ìµë¥  (ë°ˆìŠ¤í†¡ íŠ¹ì„±: ë†’ì€ ë³€ë™ì„±, ë¹„ì •ê·œë¶„í¬)
    y_true = np.random.normal(0, 0.05, n_samples)  # 5% ì¼ì¼ ë³€ë™ì„±
    y_true[::10] = np.random.normal(0, 0.2, len(y_true[::10]))  # 10%ëŠ” ê·¹ë‹¨ì  ë³€ë™
    
    # ëª¨ë¸ ì˜ˆì¸¡ë“¤ (ë‹¤ì–‘í•œ ì„±ëŠ¥ ì‹œë®¬ë ˆì´ì…˜)
    models_predictions = {
        'Perfect_Model': y_true + np.random.normal(0, 0.01, n_samples),
        'Good_Model': y_true * 0.7 + np.random.normal(0, 0.02, n_samples),  
        'Contrarian_Model': -y_true * 0.5 + np.random.normal(0, 0.02, n_samples),
        'Random_Model': np.random.normal(0, 0.03, n_samples)
    }
    
    # í‰ê°€ ì‹¤í–‰
    evaluator = FinancialModelEvaluator()
    results = []
    
    for model_name, y_pred in models_predictions.items():
        result = evaluator.comprehensive_evaluation(y_true, y_pred, model_name)
        results.append(result)
        print("\n" + "-"*60)
    
    # ë¹„êµ ë¦¬í¬íŠ¸
    best_model = evaluator.model_comparison_report(results)
    
    return results


if __name__ == "__main__":
    print("ğŸš€ Financial Model Evaluation Framework")
    print("=" * 50)
    print("ğŸ’¡ ê¸ˆìœµ ì˜ˆì¸¡ ëª¨ë¸ì„ ìœ„í•œ ì „ë¬¸ í‰ê°€ ì§€í‘œë“¤")
    print("ğŸ“Š IC, Hit Rate, Sharpe, Drawdown ë“± í¬í•¨")
    print("=" * 50)
    
    # ë°ëª¨ ì‹¤í–‰
    demo_results = demo_evaluation()
    
    print(f"\nâœ… Demo completed! {len(demo_results)} models evaluated.")
    print("ğŸ“š ì´ ì§€í‘œë“¤ì„ ë…¼ë¬¸ì—ì„œ ì‚¬ìš©í•˜ì„¸ìš”!")

