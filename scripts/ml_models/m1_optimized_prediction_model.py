#!/Users/xavi/miniconda3/bin/python
"""
M1 Mac 8GB ìµœì í™” GME/AMC/BB ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸
ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì´ê³  ë¹ ë¥¸ ì‹¤í–‰ì„ ìœ„í•œ ìµœì í™”ëœ êµ¬í˜„
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# M1 ìµœì í™” ML ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import lightgbm as lgb
    HAS_LGB = True
except ImportError:
    HAS_LGB = False
    print("LightGBM ì„¤ì¹˜ í•„ìš”: pip install lightgbm")

try:
    from sklearn.model_selection import TimeSeriesSplit
    from sklearn.preprocessing import StandardScaler
    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
    from sklearn.ensemble import RandomForestRegressor
    HAS_SKLEARN = True
except ImportError:
    HAS_SKLEARN = False
    print("scikit-learn ì„¤ì¹˜ í•„ìš”: conda install scikit-learn")

class M1OptimizedPredictor:
    """M1 Mac 8GBì— ìµœì í™”ëœ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self, memory_limit_mb=2000):
        """
        Args:
            memory_limit_mb: ëª¨ë¸ì´ ì‚¬ìš©í•  ìµœëŒ€ ë©”ëª¨ë¦¬ (MB)
        """
        self.memory_limit = memory_limit_mb
        self.models = {}
        self.scalers = {}
        self.feature_importance = {}
        
    def load_data_efficiently(self):
        """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ ë°ì´í„° ë¡œë“œ"""
        print("ğŸ”„ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ë°ì´í„° ë¡œë”©...")
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ (ë©”ëª¨ë¦¬ ì ˆì•½)
        essential_cols = [
            'date', 'ticker', 'returns_1d', 'returns_5d',
            'reddit_surprise', 'reddit_momentum_3', 'vol_5d',
            'rsi_14', 'volume_ratio', 'market_sentiment'
        ]
        
        # Reddit ê°ì • ë°ì´í„° ë¡œë“œ (ì²­í‚¹ ë°©ì‹)
        try:
            # ì²­í¬ ë‹¨ìœ„ë¡œ ì½ì–´ì„œ ë©”ëª¨ë¦¬ ì ˆì•½
            chunks = []
            for chunk in pd.read_csv('data/reddit_sentiment.csv', 
                                   chunksize=10000,  # ì‘ì€ ì²­í¬ë¡œ ë¶„í• 
                                   parse_dates=['timestamp'],
                                   usecols=['timestamp', 'finbert_score', 'emotion_score']):
                
                # 2021ë…„ ë°ì´í„°ë§Œ í•„í„°ë§
                chunk_2021 = chunk[chunk['timestamp'].dt.year == 2021]
                if len(chunk_2021) > 0:
                    chunks.append(chunk_2021)
                    
            sentiment_df = pd.concat(chunks, ignore_index=True) if chunks else pd.DataFrame()
            print(f"âœ… ê°ì • ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(sentiment_df):,}ê°œ ë ˆì½”ë“œ")
            
        except FileNotFoundError:
            print("âŒ Reddit ê°ì • ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            sentiment_df = pd.DataFrame()
        
        # ê¸°ë³¸ íŠ¹ì„± ë°ì´í„° ë¡œë“œ
        try:
            feature_files = [
                'data/colab_datasets/tabular_train_20250814_031335.csv',
                'data/colab_datasets/tabular_val_20250814_031335.csv',
                'data/colab_datasets/tabular_test_20250814_031335.csv'
            ]
            
            dfs = []
            for file in feature_files:
                try:
                    # ì»¬ëŸ¼ ì²´í¬ í›„ ë¡œë“œ
                    available_cols = pd.read_csv(file, nrows=1).columns
                    use_cols = [c for c in essential_cols if c in available_cols]
                    
                    df_chunk = pd.read_csv(file, usecols=use_cols)
                    df_chunk['date'] = pd.to_datetime(df_chunk['date'])
                    dfs.append(df_chunk)
                    
                except Exception as e:
                    print(f"âš ï¸ {file} ë¡œë“œ ì‹¤íŒ¨: {e}")
                    
            main_df = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()
            print(f"âœ… ë©”ì¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(main_df):,}ê°œ ë ˆì½”ë“œ")
            
        except Exception as e:
            print(f"âŒ ë©”ì¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            main_df = pd.DataFrame()
            
        return main_df, sentiment_df
    
    def create_memory_efficient_features(self, df):
        """ë©”ëª¨ë¦¬ íš¨ìœ¨ì  íŠ¹ì„± ìƒì„±"""
        print("ğŸ”§ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  íŠ¹ì„± ìƒì„±...")
        
        if df.empty:
            return df
            
        df = df.sort_values(['ticker', 'date']).reset_index(drop=True)
        
        # ê¸°ë³¸ íŠ¹ì„±ë“¤ (float32ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½)
        df['contrarian_signal'] = (-df['reddit_surprise']).astype('float32')
        df['momentum_signal'] = df['reddit_momentum_3'].astype('float32')
        df['volatility_adj'] = (df['vol_5d'] * df['volume_ratio']).astype('float32')
        
        # ì´ë™í‰ê·  (ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ê³„ì‚°)
        for ticker in df['ticker'].unique():
            mask = df['ticker'] == ticker
            df.loc[mask, 'returns_ma_5'] = (df.loc[mask, 'returns_1d']
                                           .rolling(5, min_periods=1)
                                           .mean().astype('float32'))
        
        # ë¶ˆí•„ìš”í•œ ì¤‘ê°„ ë³€ìˆ˜ ì •ë¦¬
        import gc
        gc.collect()
        
        return df
    
    def train_lightweight_models(self, df, target_stocks=['GME', 'AMC', 'BB']):
        """ê°€ë²¼ìš´ ëª¨ë¸ë“¤ í›ˆë ¨ (M1 8GB ìµœì í™”)"""
        print("ğŸ‹ï¸ M1 ìµœì í™” ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        
        results = {}
        
        for stock in target_stocks:
            if stock not in df['ticker'].values:
                print(f"âš ï¸ {stock} ë°ì´í„° ì—†ìŒ")
                continue
                
            stock_data = df[df['ticker'] == stock].copy()
            if len(stock_data) < 100:
                print(f"âš ï¸ {stock} ë°ì´í„° ë¶€ì¡± ({len(stock_data)}ê°œ)")
                continue
                
            print(f"ğŸ“ˆ {stock} ëª¨ë¸ í›ˆë ¨ ì¤‘...")
            
            # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ì¤€ë¹„
            feature_cols = ['contrarian_signal', 'momentum_signal', 'volatility_adj', 
                           'rsi_14', 'market_sentiment', 'returns_ma_5']
            available_features = [col for col in feature_cols if col in stock_data.columns]
            
            X = stock_data[available_features].fillna(0)
            y = stock_data['returns_1d'].fillna(0)
            
            # ì‹œê³„ì—´ ë¶„í• 
            tscv = TimeSeriesSplit(n_splits=3)  # ì‘ì€ ë¶„í• ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
            
            # ìŠ¤ì¼€ì¼ë§
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            
            # ëª¨ë¸ë“¤ í›ˆë ¨
            models = {}
            
            # 1. LightGBM (M1 ìµœì í™”, ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
            if HAS_LGB:
                lgb_params = {
                    'objective': 'regression',
                    'metric': 'rmse',
                    'boosting_type': 'gbdt',
                    'num_leaves': 15,  # ì‘ê²Œ ì„¤ì • (ë©”ëª¨ë¦¬ ì ˆì•½)
                    'learning_rate': 0.1,
                    'max_depth': 4,  # ì–•ê²Œ ì„¤ì •
                    'min_data_in_leaf': 10,
                    'lambda_l2': 0.1,
                    'verbosity': -1,
                    'num_threads': 8,  # M1 8ì½”ì–´ í™œìš©
                    'max_bin': 255  # ë©”ëª¨ë¦¬ ì ˆì•½
                }
                
                lgb_model = lgb.LGBMRegressor(**lgb_params, n_estimators=100)
                lgb_model.fit(X_scaled, y)
                models['LightGBM'] = lgb_model
                
            # 2. ê°€ë²¼ìš´ Random Forest
            if HAS_SKLEARN:
                rf_model = RandomForestRegressor(
                    n_estimators=50,  # ì‘ê²Œ ì„¤ì •
                    max_depth=8,
                    min_samples_split=10,
                    n_jobs=4,  # M1 ì½”ì–´ í™œìš©
                    random_state=42
                )
                rf_model.fit(X_scaled, y)
                models['RandomForest'] = rf_model
            
            # ëª¨ë¸ í‰ê°€
            train_scores = {}
            for name, model in models.items():
                y_pred = model.predict(X_scaled)
                rmse = np.sqrt(mean_squared_error(y, y_pred))
                r2 = r2_score(y, y_pred)
                
                train_scores[name] = {
                    'RMSE': rmse,
                    'RÂ²': r2,
                    'MAE': mean_absolute_error(y, y_pred)
                }
                
                print(f"  {name}: RMSE={rmse:.4f}, RÂ²={r2:.4f}")
            
            results[stock] = {
                'models': models,
                'scaler': scaler,
                'features': available_features,
                'scores': train_scores,
                'data_points': len(stock_data)
            }
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            import gc
            gc.collect()
        
        self.models = results
        return results
    
    def predict_next_prices(self, days=5):
        """ë‹¤ìŒ ë©°ì¹ ê°„ì˜ ê°€ê²© ì˜ˆì¸¡"""
        print(f"ğŸ”® í–¥í›„ {days}ì¼ ê°€ê²© ì˜ˆì¸¡...")
        
        predictions = {}
        
        for stock, model_data in self.models.items():
            print(f"ğŸ“Š {stock} ì˜ˆì¸¡ ì¤‘...")
            
            # ê°€ì¥ ì„±ëŠ¥ ì¢‹ì€ ëª¨ë¸ ì„ íƒ
            best_model_name = min(model_data['scores'].keys(), 
                                key=lambda x: model_data['scores'][x]['RMSE'])
            best_model = model_data['models'][best_model_name]
            
            # ë§ˆì§€ë§‰ íŠ¹ì„±ê°’ìœ¼ë¡œ ì˜ˆì¸¡ (ì‹¤ì œë¡œëŠ” ì‹¤ì‹œê°„ ë°ì´í„° í•„ìš”)
            # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
            last_features = np.random.randn(1, len(model_data['features']))  # ì˜ˆì‹œ
            last_features_scaled = model_data['scaler'].transform(last_features)
            
            pred_returns = best_model.predict(last_features_scaled)[0]
            
            predictions[stock] = {
                'predicted_return': pred_returns,
                'model_used': best_model_name,
                'confidence': model_data['scores'][best_model_name]['RÂ²']
            }
            
            print(f"  ì˜ˆìƒ ìˆ˜ìµë¥ : {pred_returns:.4f} ({best_model_name})")
        
        return predictions
    
    def generate_trading_signals(self, predictions, threshold=0.02):
        """ê±°ë˜ ì‹ í˜¸ ìƒì„±"""
        print("ğŸ“¡ ê±°ë˜ ì‹ í˜¸ ìƒì„±...")
        
        signals = {}
        
        for stock, pred in predictions.items():
            pred_return = pred['predicted_return']
            confidence = pred['confidence']
            
            # ì‹ í˜¸ ìƒì„± ë¡œì§
            if pred_return > threshold and confidence > 0.1:
                signal = 'BUY'
                strength = min(abs(pred_return) * confidence, 1.0)
            elif pred_return < -threshold and confidence > 0.1:
                signal = 'SELL' 
                strength = min(abs(pred_return) * confidence, 1.0)
            else:
                signal = 'HOLD'
                strength = 0.0
            
            signals[stock] = {
                'signal': signal,
                'strength': strength,
                'predicted_return': pred_return,
                'confidence': confidence
            }
            
            print(f"  {stock}: {signal} (ê°•ë„: {strength:.3f})")
        
        return signals

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ M1 Mac 8GB GME/AMC/BB ê°€ê²© ì˜ˆì¸¡ê¸° ì‹œì‘!")
    print("=" * 50)
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    predictor = M1OptimizedPredictor(memory_limit_mb=2000)
    
    # ë°ì´í„° ë¡œë“œ
    main_df, sentiment_df = predictor.load_data_efficiently()
    
    if main_df.empty:
        print("âŒ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ í™˜ê²½ì„ ì„¤ì •í•˜ì„¸ìš”:")
        print("bash setup_m1_ml_environment.sh")
        return
    
    # íŠ¹ì„± ìƒì„±
    enhanced_df = predictor.create_memory_efficient_features(main_df)
    
    # ëª¨ë¸ í›ˆë ¨
    results = predictor.train_lightweight_models(enhanced_df)
    
    if not results:
        print("âŒ ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨")
        return
    
    # ì˜ˆì¸¡ ì‹¤í–‰
    predictions = predictor.predict_next_prices(days=5)
    
    # ê±°ë˜ ì‹ í˜¸ ìƒì„±
    signals = predictor.generate_trading_signals(predictions)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 50)
    print("ğŸ¯ ìµœì¢… íˆ¬ì ê¶Œê³ :")
    print("=" * 50)
    
    for stock, signal_data in signals.items():
        signal = signal_data['signal']
        strength = signal_data['strength']
        pred_return = signal_data['predicted_return']
        
        emoji = "ğŸ”¥" if signal == 'BUY' else "ğŸ“‰" if signal == 'SELL' else "ğŸ˜´"
        print(f"{emoji} {stock}: {signal} (ì˜ˆìƒìˆ˜ìµë¥ : {pred_return:.2%}, ì‹ ë¢°ë„: {strength:.1%})")
    
    print("\nğŸ’¡ M1 8GBë¡œë„ ì¶©ë¶„íˆ ë¹ ë¥´ê³  ì •í™•í•œ ì˜ˆì¸¡ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!")

if __name__ == "__main__":
    main()
