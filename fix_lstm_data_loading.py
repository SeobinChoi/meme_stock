#!/usr/bin/env python3
"""
ğŸš€ LSTM ë°ì´í„° ë¡œë”© ë¬¸ì œ í•´ê²° ìŠ¤í¬ë¦½íŠ¸
A100 GPU í™˜ê²½ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ì‹¤í–‰ë˜ë„ë¡ ìµœì í™”
"""

import numpy as np
import pandas as pd
import torch
from typing import Tuple, List, Optional

def fix_sequence_data_loading(sequences_data: np.lib.npyio.NpzFile, 
                             metadata: dict) -> Tuple[np.ndarray, np.ndarray, List]:
    """
    ì‹œí€€ìŠ¤ ë°ì´í„° ë¡œë”© ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ê°•í™”ëœ í•¨ìˆ˜
    
    Args:
        sequences_data: np.load()ë¡œ ë¡œë“œëœ .npz íŒŒì¼
        metadata: ë°ì´í„°ì…‹ ë©”íƒ€ë°ì´í„°
        
    Returns:
        X_seq: (samples, timesteps, features) í˜•íƒœì˜ ì‹œí€€ìŠ¤ ë°ì´í„°
        y_seq: íƒ€ê²Ÿ ê°’ë“¤
        dates_seq: ë‚ ì§œ ì •ë³´
    """
    
    print("ğŸ”§ Fixing sequence data loading...")
    
    all_sequences = []
    all_targets = []
    all_dates = []
    
    # ê° í‹°ì»¤ë³„ë¡œ ë°ì´í„° ì²˜ë¦¬
    for ticker in metadata['tickers']:
        print(f"   Processing {ticker}...")
        
        if f'{ticker}_sequences' in sequences_data:
            sequences = sequences_data[f'{ticker}_sequences']
            targets = sequences_data[f'{ticker}_targets_1d']
            dates = sequences_data[f'{ticker}_dates']
            
            print(f"     Raw shape: {sequences.shape}, dtype: {sequences.dtype}")
            
            # ë¬¸ìì—´ ë°ì´í„° íƒ€ì… ë¬¸ì œ í•´ê²°
            if sequences.dtype == object:
                print(f"     âš ï¸ Object dtype detected, cleaning...")
                sequences = clean_object_sequences(sequences, ticker)
                
                if sequences is None:
                    print(f"     âŒ Skipping {ticker} - no valid numeric data")
                    continue
            
            # NaN/Inf ê°’ ì •ë¦¬
            sequences = clean_nan_inf(sequences)
            
            # float32ë¡œ ë³€í™˜ (A100 ìµœì í™”)
            sequences = sequences.astype(np.float32)
            
            all_sequences.append(sequences)
            all_targets.extend(targets)
            all_dates.extend(dates)
            
            print(f"     âœ… Cleaned: {sequences.shape}, dtype: {sequences.dtype}")
        else:
            print(f"     âš ï¸ {ticker} sequences not found")
    
    if not all_sequences:
        raise ValueError("âŒ No valid sequences found after cleaning!")
    
    # ëª¨ë“  ì‹œí€€ìŠ¤ ê²°í•©
    X_seq = np.vstack(all_sequences).astype(np.float32)
    y_seq = np.array(all_targets, dtype=np.float32)
    
    print(f"âœ… Final data prepared:")
    print(f"   X_seq: {X_seq.shape}, dtype: {X_seq.dtype}")
    print(f"   y_seq: {y_seq.shape}, dtype: {y_seq.dtype}")
    
    return X_seq, y_seq, all_dates

def clean_object_sequences(sequences: np.ndarray, ticker: str) -> Optional[np.ndarray]:
    """
    object dtype ì‹œí€€ìŠ¤ì—ì„œ ìˆ«ì ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
    """
    
    print(f"     ğŸ” Cleaning {ticker} sequences...")
    
    # ê° ì»¬ëŸ¼ì„ floatë¡œ ë³€í™˜ ì‹œë„
    numeric_cols = []
    cleaned_sequences = []
    
    for i in range(sequences.shape[2]):
        try:
            # í•´ë‹¹ ì»¬ëŸ¼ì„ floatë¡œ ë³€í™˜
            test_col = sequences[:, :, i].astype(np.float64)
            
            # NaNì´ ì•„ë‹Œ ê°’ì´ ìˆëŠ”ì§€ í™•ì¸
            if np.any(np.isfinite(test_col)):
                numeric_cols.append(i)
                cleaned_sequences.append(test_col)
            else:
                print(f"       Column {i}: all NaN, skipping")
                
        except (ValueError, TypeError) as e:
            print(f"       Column {i}: conversion failed ({e}), skipping")
            continue
    
    if len(numeric_cols) == 0:
        print(f"     âŒ No numeric columns found in {ticker}")
        return None
    
    # ìœ íš¨í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ì—¬ 3D ë°°ì—´ ì¬êµ¬ì„±
    cleaned = np.stack(cleaned_sequences, axis=2)
    
    print(f"       Kept {len(numeric_cols)}/{sequences.shape[2]} columns")
    print(f"       New shape: {cleaned.shape}")
    
    return cleaned

def clean_nan_inf(sequences: np.ndarray) -> np.ndarray:
    """
    NaNê³¼ Inf ê°’ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
    """
    
    # NaNì„ 0ìœ¼ë¡œ, Infë¥¼ 0ìœ¼ë¡œ ë³€í™˜
    cleaned = np.nan_to_num(sequences, nan=0.0, posinf=0.0, neginf=0.0)
    
    # ê·¹ë‹¨ê°’ í´ë¦¬í•‘ (í‘œì¤€í¸ì°¨ì˜ 5ë°°)
    for i in range(cleaned.shape[2]):
        col_data = cleaned[:, :, i]
        if np.std(col_data) > 0:
            mean_val = np.mean(col_data)
            std_val = np.std(col_data)
            lower_bound = mean_val - 5 * std_val
            upper_bound = mean_val + 5 * std_val
            col_data = np.clip(col_data, lower_bound, upper_bound)
            cleaned[:, :, i] = col_data
    
    return cleaned

def validate_sequence_dimensions(X_seq: np.ndarray, y_seq: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """
    ì‹œí€€ìŠ¤ ì°¨ì›ê³¼ ë°ì´í„° í’ˆì§ˆ ê²€ì¦
    """
    
    print("ğŸ” Validating sequence dimensions...")
    
    # ì°¨ì› ê²€ì¦
    if len(X_seq.shape) != 3:
        raise ValueError(f"âŒ Expected 3D array, got {len(X_seq.shape)}D: {X_seq.shape}")
    
    if X_seq.shape[0] != len(y_seq):
        raise ValueError(f"âŒ Sample count mismatch: X={X_seq.shape[0]}, y={len(y_seq)}")
    
    # ë°ì´í„° íƒ€ì… ê²€ì¦
    if not np.issubdtype(X_seq.dtype, np.floating):
        raise ValueError(f"âŒ X_seq must be float, got {X_seq.dtype}")
    
    if not np.issubdtype(y_seq.dtype, np.floating):
        raise ValueError(f"âŒ y_seq must be float, got {y_seq.dtype}")
    
    # NaN/Inf ìµœì¢… ê²€ì‚¬
    if np.any(np.isnan(X_seq)) or np.any(np.isinf(X_seq)):
        print("âš ï¸ Final cleanup: removing remaining NaN/Inf...")
        X_seq = np.nan_to_num(X_seq, nan=0.0, posinf=0.0, neginf=0.0)
    
    print("âœ… Sequence validation passed!")
    print(f"   Final X_seq: {X_seq.shape}, dtype: {X_seq.dtype}")
    print(f"   Final y_seq: {y_seq.shape}, dtype: {y_seq.dtype}")
    
    return X_seq, y_seq

def prepare_train_val_test_split(X_seq: np.ndarray, y_seq: np.ndarray, 
                                dates_seq: List, train_ratio: float = 0.7, 
                                val_ratio: float = 0.15) -> Tuple:
    """
    í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¶„í• 
    """
    
    print("ğŸ“Š Preparing train/val/test split...")
    
    # ë‚ ì§œ ê¸°ë°˜ ë¶„í• 
    dates = pd.to_datetime(dates_seq)
    
    # ë‚ ì§œ ì •ë ¬
    sorted_indices = np.argsort(dates)
    X_sorted = X_seq[sorted_indices]
    y_sorted = y_seq[sorted_indices]
    dates_sorted = dates[sorted_indices]
    
    # ë¶„í•  ì§€ì  ê³„ì‚°
    n_samples = len(X_sorted)
    train_end = int(n_samples * train_ratio)
    val_end = int(n_samples * (train_ratio + val_ratio))
    
    # ë¶„í• 
    X_train = X_sorted[:train_end]
    X_val = X_sorted[train_end:val_end]
    X_test = X_sorted[val_end:]
    
    y_train = y_sorted[:train_end]
    y_val = y_sorted[train_end:val_end]
    y_test = y_sorted[val_end:]
    
    dates_train = dates_sorted[:train_end]
    dates_val = dates_sorted[train_end:val_end]
    dates_test = dates_sorted[val_end:]
    
    print(f"âœ… Split completed:")
    print(f"   Train: {X_train.shape[0]} samples ({dates_train.min().date()} to {dates_train.max().date()})")
    print(f"   Val: {X_val.shape[0]} samples ({dates_val.min().date()} to {dates_val.max().date()})")
    print(f"   Test: {X_test.shape[0]} samples ({dates_test.min().date()} to {dates_test.max().date()})")
    
    return (X_train, X_val, X_test, 
            y_train, y_val, y_test,
            dates_train, dates_val, dates_test)

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)
    """
    print("ğŸš€ LSTM Data Loading Fix Script")
    print("=" * 50)
    
    # ì‚¬ìš© ì˜ˆì‹œ
    print("ğŸ“– Usage:")
    print("1. Import this script in your Colab notebook")
    print("2. Replace prepare_sequence_data() with fix_sequence_data_loading()")
    print("3. Add validation and error handling")
    
    print("\nğŸ”§ Key fixes implemented:")
    print("   âœ… Object dtype string removal")
    print("   âœ… NaN/Inf cleaning")
    print("   âœ… Dimension validation")
    print("   âœ… A100 GPU optimization (float32)")
    print("   âœ… Robust error handling")


