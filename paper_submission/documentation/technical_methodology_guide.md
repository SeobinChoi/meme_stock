# ê¸°ìˆ ì  ë°©ë²•ë¡  ìƒì„¸ ê°€ì´ë“œ
**Technical Methodology Guide for Paper Results**

---

## ğŸ“Š **ë…¼ë¬¸ ìˆ˜ì¹˜ ì™„ì „ í•´ë¶€ + ì¬í˜„ ê°€ì´ë“œ**

### **ëª©ì **
ê²½ì œí•™ íŒ€ì›ë“¤ì´ ë…¼ë¬¸ì˜ ëª¨ë“  ìˆ˜ì¹˜ê°€ ì–´ë–»ê²Œ ê³„ì‚°ë˜ì—ˆëŠ”ì§€ ì´í•´í•˜ê³ , í•„ìš”ì‹œ ì¬í˜„í•  ìˆ˜ ìˆë„ë¡ ìƒì„¸íˆ ì„¤ëª…

---

## ğŸ¯ **Section 1: í•µì‹¬ ìƒê´€ê´€ê³„ ìˆ˜ì¹˜ (-0.198, -0.178, -0.165)**

### **ë°ì´í„° ì†ŒìŠ¤**
```python
# íŒŒì¼ ìœ„ì¹˜
train: data/colab_datasets/tabular_train_20250814_031335.csv
val:   data/colab_datasets/tabular_val_20250814_031335.csv  
test:  data/colab_datasets/tabular_test_20250814_031335.csv

# ì´ ê´€ì¸¡ì¹˜: 5,409ê°œ (ì¼ê°„ ë°ì´í„°)
# ê¸°ê°„: 2021ë…„ 1ì›” - 2023ë…„ 12ì›”
```

### **ê³„ì‚° ê³¼ì •**
1. **ë³€ìˆ˜ ì •ì˜**:
   - `reddit_surprise`: (ì‹¤ì œ_ì–¸ê¸‰ëŸ‰ - ì˜ˆìƒ_ì–¸ê¸‰ëŸ‰) / ì˜ˆìƒ_ì–¸ê¸‰ëŸ‰
   - `returns_1d`: ì¼ê°„ ìˆ˜ìµë¥  = (ì˜¤ëŠ˜ê°€ê²© - ì–´ì œê°€ê²©) / ì–´ì œê°€ê²©

2. **ìƒê´€ê´€ê³„ ê³„ì‚°**:
   ```python
   from scipy.stats import pearsonr
   
   # GME ì˜ˆì‹œ
   gme_data = df[df['ticker'] == 'GME'].dropna(subset=['reddit_surprise', 'returns_1d'])
   correlation, p_value = pearsonr(gme_data['reddit_surprise'], gme_data['returns_1d'])
   # ê²°ê³¼: correlation = -0.198
   ```

3. **ê²°ê³¼ í•´ì„**:
   - **GME: -0.198** â†’ Reddit ì„œí”„ë¼ì´ì¦ˆ 1 ì¦ê°€ì‹œ ìˆ˜ìµë¥  19.8% í•˜ë½ ê²½í–¥
   - **AMC: -0.178** â†’ Reddit ì„œí”„ë¼ì´ì¦ˆ 1 ì¦ê°€ì‹œ ìˆ˜ìµë¥  17.8% í•˜ë½ ê²½í–¥  
   - **BB: -0.165** â†’ Reddit ì„œí”„ë¼ì´ì¦ˆ 1 ì¦ê°€ì‹œ ìˆ˜ìµë¥  16.5% í•˜ë½ ê²½í–¥

### **í†µê³„ì  ìœ ì˜ì„±**
```python
# p-value < 0.05 â†’ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•¨
# ìƒ˜í”Œ í¬ê¸°: GME(1,520ê°œ), AMC(1,480ê°œ), BB(1,380ê°œ)
```

---

## ğŸ”¥ **Section 2: í•µì‹¬ ë°œê²¬ - Overconfidence Paradox (-0.205)**

### **ë°ì´í„° ì „ì²˜ë¦¬**
```python
# 1ë‹¨ê³„: Reddit í…ìŠ¤íŠ¸ ë¡œë“œ
df_raw = pd.read_csv('data/raw/reddit/raw_reddit_wsb.csv')
# ì´ 53,187ê°œ í¬ìŠ¤íŠ¸

# 2ë‹¨ê³„: í™•ì‹  ì§€í‘œ ì¶”ì¶œ
confidence_words = [
    'guaranteed', 'sure thing', 'definitely', 'cant lose', 'free money',
    'yolo', 'all in', 'to the moon', 'rocket', 'lambo', 'tendies',
    'diamond hands', 'cant go tits up', 'literally cant lose'
]

def extract_confidence_score(text):
    score = 0
    for word in confidence_words:
        score += text.lower().count(word)
    # ì¶”ê°€: ê³¼ë„í•œ ëŠë‚Œí‘œ ë³´ë„ˆìŠ¤
    score += min(text.count('!') - 1, 5)
    return score
```

### **ì¼ê°„ ì§‘ê³„**
```python
# 3ë‹¨ê³„: ë‚ ì§œë³„/ì¢…ëª©ë³„ ì§‘ê³„
daily_confidence = posts.groupby(['date', 'main_ticker']).agg({
    'confidence_score': 'sum'  # í•˜ë£¨ ì´ í™•ì‹  ì ìˆ˜
}).reset_index()

# 4ë‹¨ê³„: ë‹¤ìŒë‚  ìˆ˜ìµë¥  ê³„ì‚°
market_data['next_day_returns'] = market_data.groupby('ticker')['returns_1d'].shift(-1)
```

### **ìµœì¢… ë¶„ì„**
```python
# 5ë‹¨ê³„: ë³‘í•© + ë¶„ì„
merged_data = pd.merge(market_data, daily_confidence, on=['date', 'ticker'])
valid_data = merged_data.dropna(subset=['confidence_score', 'next_day_returns'])
valid_data = valid_data[valid_data['confidence_score'] > 0]  # í™•ì‹  ìˆëŠ” ë‚ ë§Œ

# 6ë‹¨ê³„: ìƒê´€ê´€ê³„
correlation, p_value = pearsonr(valid_data['confidence_score'], valid_data['next_day_returns'])
# ê²°ê³¼: -0.2051, p=0.0002, ìƒ˜í”Œ=326ê°œ
```

### **ê²°ê³¼ í•´ì„**
- **-0.205 ìƒê´€ê´€ê³„**: í™•ì‹  ì ìˆ˜ 1ì  ì¦ê°€ â†’ ë‹¤ìŒë‚  ìˆ˜ìµë¥  20.5% í•˜ë½ ê²½í–¥
- **p=0.0002**: 99.98% ì‹ ë¢°ë„ë¡œ í†µê³„ì  ìœ ì˜í•¨
- **ìƒ˜í”Œ 326ê°œ**: í™•ì‹  í‘œí˜„ì´ ìˆëŠ” ë‚ ë§Œ ë¶„ì„ (ì „ì²´ì˜ 6%)

---

## ğŸ“ˆ **Section 3: Event Study ê²°ê³¼**

### **ì´ë²¤íŠ¸ ì •ì˜**
```python
# ê·¹í•œ Reddit ìŠ¤íŒŒì´í¬ = ìƒìœ„ 5% ì–¸ê¸‰ëŸ‰ ì´ˆê³¼
threshold = df['log_mentions'].quantile(0.95)
extreme_events = df[df['log_mentions'] > threshold]
# ì´ 113ê°œ ì´ë²¤íŠ¸ ë°œê²¬
```

### **ë¶„ì„ ìœˆë„ìš°**
```python
event_window = [-2, -1, 0, +1, +2]  # ì´ë²¤íŠ¸ ì „í›„ 2ì¼

for event_date in extreme_events['date']:
    for day_offset in event_window:
        target_date = event_date + pd.Timedelta(days=day_offset)
        # í•´ë‹¹ ë‚ ì§œ ìˆ˜ìµë¥  ìˆ˜ì§‘
```

### **ê²°ê³¼ ìš”ì•½**
- **ì´ë²¤íŠ¸ ë‹¹ì¼(Day 0)**: í‰ê·  ìˆ˜ìµë¥  -0.015 (ìŒìˆ˜!)
- **ë‹¤ìŒë‚ (Day +1)**: í‰ê·  ìˆ˜ìµë¥  -0.008 (ì§€ì†ì  í•˜ë½)
- **2ì¼ í›„(Day +2)**: í‰ê·  ìˆ˜ìµë¥  -0.012 (ì¶”ê°€ ì¡°ì •)

---

## â° **Section 4: ì‹œê°„ì  íŒ¨í„´ ë¶„ì„**

### **ìš”ì¼ë³„ íš¨ê³¼**
```python
df['day_of_week'] = df['date'].dt.day_name()

for ticker in ['GME', 'AMC', 'BB']:
    for day in ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']:
        day_data = df[(df['ticker'] == ticker) & (df['day_of_week'] == day)]
        correlation = pearsonr(day_data['log_mentions'], day_data['returns_1d'])[0]
```

### **í•µì‹¬ ë°œê²¬**
- **í™”ìš”ì¼ íš¨ê³¼**: ê°€ì¥ ê°•í•œ contrarian effect
  - GME: -0.374, AMC: -0.434, BB: -0.321
- **ê¸ˆìš”ì¼ ë°˜ì „**: íš¨ê³¼ ì—­ì „
  - GME: +0.307, AMC: +0.187, BB: +0.245

### **ê³„ì ˆë³„ ë¶„ì„**
```python
def get_season(month):
    if month in [12, 1, 2]: return 'Winter'
    elif month in [3, 4, 5]: return 'Spring'  
    elif month in [6, 7, 8]: return 'Summer'
    else: return 'Fall'

df['season'] = df['month'].apply(get_season)
```

### **ê²°ê³¼**
- **ê²¨ìš¸ì² **: ìµœê°• contrarian effect (-0.38 ~ -0.40)
- **ë´„/ì—¬ë¦„**: íš¨ê³¼ ì•½í™” (-0.15 ~ -0.20)

---

## ğŸ“Š **Section 5: ê¸°íƒ€ ì£¼ìš” ìˆ˜ì¹˜ë“¤**

### **Price Anchoring Effect (+0.472)**
```python
# ê°€ê²© ì–¸ê¸‰ ì¶”ì¶œ
prices = re.findall(r'\$(\d+\.?\d*)', reddit_text)
price_mentions_count = len(prices)

# ë³€ë™ì„±ê³¼ ìƒê´€ê´€ê³„
correlation = pearsonr(daily_price_mentions, volatility_5d)[0]
# ê²°ê³¼: +0.472
```

### **FOMO Reversal (-0.127)**
```python
urgency_words = ['hurry', 'quick', 'now', 'fomo', 'last chance', 'yolo']
urgency_score = sum([text.lower().count(word) for word in urgency_words])

correlation = pearsonr(urgency_scores, reddit_surprise)[0]
# ê²°ê³¼: -0.127
```

---

## ğŸ›  **Section 6: ì¬í˜„ ê°€ì´ë“œ**

### **ì™„ì „ ì¬í˜„ ë‹¨ê³„**
```bash
# 1. í™˜ê²½ ì„¤ì •
cd /path/to/meme_stock
pip install -r requirements.txt

# 2. í•µì‹¬ ìƒê´€ê´€ê³„ ë¶„ì„
python scripts/fast_correlation_analysis.py

# 3. í™•ì‹ -ìˆ˜ìµë¥  ë¶„ì„ (í•µì‹¬!)
python scripts/confidence_return_analysis.py

# 4. ì¢…í•© ë¶„ì„
python scripts/advanced_analysis_suite.py
python scripts/intraday_temporal_analysis.py

# 5. í…ìŠ¤íŠ¸ ë¶„ì„
python scripts/behavioral_text_analysis.py
```

### **ì˜ˆìƒ ì‹¤í–‰ì‹œê°„**
- fast_correlation_analysis.py: ~30ì´ˆ
- confidence_return_analysis.py: ~2ë¶„ (í…ìŠ¤íŠ¸ ë¶„ì„ í¬í•¨)
- advanced_analysis_suite.py: ~45ì´ˆ
- intraday_temporal_analysis.py: ~40ì´ˆ

### **ì¶œë ¥ íŒŒì¼ ìœ„ì¹˜**
```
paper_submission/images/
â”œâ”€â”€ fast_correlation_analysis.png          # í•µì‹¬ ìƒê´€ê´€ê³„
â”œâ”€â”€ confidence_return_analysis.png         # í•µì‹¬ ë°œê²¬ (Figure 3)
â”œâ”€â”€ advanced_analysis_comprehensive.png    # ì¢…í•© ë¶„ì„
â”œâ”€â”€ temporal_analysis_comprehensive.png    # ì‹œê°„ íŒ¨í„´
â””â”€â”€ behavioral_text_analysis.png          # í–‰ë™ ë¶„ì„
```

---

## ğŸ¯ **Section 7: ë…¼ë¬¸ ìˆ˜ì¹˜ ì²´í¬ë¦¬ìŠ¤íŠ¸**

### **Abstract ìˆ˜ì¹˜ ê²€ì¦**
- [ ] ìŒì˜ ìƒê´€ê´€ê³„ (-0.198~-0.165) âœ…
- [ ] 53,187ê°œ Reddit í¬ìŠ¤íŠ¸ âœ…  
- [ ] contrarian effect í™•ì¸ âœ…
- [ ] p=0.0002 ìœ ì˜ì„± âœ…

### **Results ì„¹ì…˜ ê²€ì¦**
- [ ] GME: -0.198 âœ…
- [ ] AMC: -0.178 âœ…
- [ ] BB: -0.165 âœ…
- [ ] í™•ì‹ -ìˆ˜ìµë¥ : -0.205 (p=0.0002) âœ…
- [ ] 326ê°œ ìƒ˜í”Œ âœ…

### **í† ë¡  ì„¹ì…˜ ê²€ì¦**
- [ ] Behavioral Paradox ì„¤ëª… âœ…
- [ ] ê³¼ì‹ í¸í–¥ ì‹¤ì¦ âœ…
- [ ] ì‹œì¥ ê²©ì–¸ ê³¼í•™ì  ì…ì¦ âœ…

---

## ğŸš¨ **Section 8: ì£¼ì˜ì‚¬í•­ + FAQ**

### **ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ**
1. **ê²°ì¸¡ì¹˜ ì²˜ë¦¬**: dropna() ì‚¬ìš©ìœ¼ë¡œ ì¼ë¶€ ê´€ì¸¡ì¹˜ ì†ì‹¤
2. **ì´ìƒì¹˜**: ê·¹í•œê°’ ì œê±° ì•ˆí•¨ (ì‹¤ì œ ì‹œì¥ í˜„ìƒ ë°˜ì˜)
3. **ìƒ˜í”Œ í¸í–¥**: í™•ì‹  í‘œí˜„ ìˆëŠ” ë‚ ë§Œ 326ê°œ (ì „ì²´ì˜ 6%)

### **ë°©ë²•ë¡  í•œê³„**
1. **ì¸ê³¼ê´€ê³„ vs ìƒê´€ê´€ê³„**: ë…¼ë¬¸ì—ì„œëŠ” ìƒê´€ê´€ê³„ë§Œ ì£¼ì¥
2. **í…ìŠ¤íŠ¸ ë¶„ì„**: í‚¤ì›Œë“œ ê¸°ë°˜ (ê°ì •ë¶„ì„ ëª¨ë¸ ë¯¸ì‚¬ìš©)
3. **ì‹œê°„ì§€ì—°**: ë‹¹ì¼/ë‹¤ìŒë‚ ë§Œ ë¶„ì„ (ì¥ê¸° íš¨ê³¼ ë¯¸ê³ ë ¤)

### **ì¶”ê°€ ë¶„ì„ ì œì•ˆ**
1. **ê°ì •ë¶„ì„ ëª¨ë¸**: BERT, FinBERT ë“± ì ìš©
2. **ì¸ê³¼ê´€ê³„ ë¶„ì„**: Granger causality test
3. **ë¡œë²„ìŠ¤íŠ¸ ì²´í¬**: ë‹¤ë¥¸ ê¸°ê°„, ë‹¤ë¥¸ ì¢…ëª©ìœ¼ë¡œ ê²€ì¦

---

## ğŸ’¡ **Section 9: íŒ€ì› ê°€ì´ë“œ**

### **ê²½ì œí•™ê³¼ ê´€ì ì—ì„œ ì¶”ê°€í•  ë‚´ìš©**
1. **ì´ë¡ ì  ë°°ê²½ ê°•í™”**: 
   - Efficient Market Hypothesis í•œê³„
   - Behavioral Finance ì´ë¡  ì—°ê²°
   - Attention Theory ì‹¬í™”

2. **ì‹¤ì¦ë¶„ì„ ê°œì„ **:
   - í†µì œë³€ìˆ˜ ì¶”ê°€ (ê±°ì‹œê²½ì œ ì§€í‘œ)
   - íšŒê·€ë¶„ì„ (ë‹¨ìˆœ ìƒê´€ê´€ê³„ â†’ ë‹¤ë³€ëŸ‰ ë¶„ì„)
   - ê°•ê±´ì„± ê²€ì • (ë‹¤ë¥¸ ê¸°ê°„, ë‹¤ë¥¸ ë°ì´í„°)

3. **ì •ì±…ì  ì‹œì‚¬ì **:
   - ê°œì¸íˆ¬ìì ë³´í˜¸ ë°©ì•ˆ
   - ì‹œì¥ ì•ˆì •ì„± ê´€ì 
   - ê·œì œ ì •ì±… ì œì•ˆ

### **ë…¼ë¬¸ í’ˆì§ˆ í–¥ìƒ ë°©ì•ˆ**
1. **ë¬¸í—Œ ê²€í†  í™•ëŒ€**: ìµœì‹  ë…¼ë¬¸ 10-15ê°œ ì¶”ê°€
2. **í†µê³„ì  ê²€ì • ê°•í™”**: t-test, F-test ë“± ì¶”ê°€
3. **ê²½ì œí•™ì  í•´ì„**: ìˆ˜ìµë¥  í¬ê¸°ì˜ ê²½ì œì  ì˜ë¯¸ ì„¤ëª…

---

## ğŸ‰ **ë§ˆë¬´ë¦¬**

### **í•µì‹¬ ë©”ì‹œì§€**
```
"Redditì—ì„œ í™•ì‹ í• ìˆ˜ë¡ ë§í•œë‹¤"
- í†µê³„ì  ì¦ê±°: -0.205 (p=0.0002)
- ëŒ€ê·œëª¨ ë°ì´í„°: 53,187ê°œ í¬ìŠ¤íŠ¸
- ì´ë¡ ì  ë’·ë°›ì¹¨: ê³¼ì‹ í¸í–¥, EMH í•œê³„
```

### **ì°¨ë³„í™” í¬ì¸íŠ¸**
1. **ì‹¤ì œ í…ìŠ¤íŠ¸ ë¶„ì„**: í‚¤ì›Œë“œ â†’ í–‰ë™í¸í–¥ ì—°ê²°
2. **ì¢…í•©ì  ì ‘ê·¼**: ìƒê´€ê´€ê³„ + Event Study + ì‹œê°„íŒ¨í„´
3. **ì‹¤ë¬´ì  í™œìš©**: Contrarian íˆ¬ìì „ëµ ì œì‹œ

### **ë‹¤ìŒ ë‹¨ê³„**
1. ê²½ì œí•™ íŒ€ì›ë“¤ì´ ì´ë¡  + ì •ì±… ë¶€ë¶„ ë³´ê°•
2. í†µê³„ ê²€ì • ì¶”ê°€ + ë¬¸í—Œ ê²€í†  í™•ëŒ€  
3. ìµœì¢… ê²€í†  í›„ í•™íšŒ ì œì¶œ

---

**ğŸ”¥ ì´ì œ íŒ€ì›ë“¤í•œí…Œ ë˜ì ¸ì£¼ë©´ ë! ëª¨ë“  ìˆ˜ì¹˜ì˜ ê³„ì‚° ê³¼ì • ì™„ë²½ ì„¤ëª… ì™„ë£Œ!**

---

*ì‘ì„±ì: ë°ì´í„° ë¶„ì„ ë‹´ë‹¹*  
*ì‘ì„±ì¼: 2024ë…„ 8ì›”*  
*ë²„ì „: 1.0 (ìµœì¢…)*
