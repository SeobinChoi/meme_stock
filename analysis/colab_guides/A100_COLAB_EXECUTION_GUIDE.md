# ğŸš€ A100 GPU Colab ì‹¤í–‰ ê°€ì´ë“œ

## ğŸ¯ **ì£¼ìš” ìˆ˜ì • ì‚¬í•­ ìš”ì•½**

### **1. LSTM ë°ì´í„° ë¡œë”© ë¬¸ì œ ì™„ì „ í•´ê²°**
- **ë¬¸ìì—´ ë°ì´í„° íƒ€ì… ì˜¤ë¥˜**: `sequences.dtype == object` ê²€ì‚¬ ë° ìˆ«ì ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
- **ì°¨ì› ê²€ì¦**: 3D ë°°ì—´ êµ¬ì¡° ê°•ì œ í™•ì¸
- **NaN/Inf ì²˜ë¦¬**: `np.nan_to_num()` ìœ¼ë¡œ ì•ˆì „í•œ ë°ì´í„° ë³€í™˜

### **2. A100 GPU ìµœì í™”**
- **í˜¼í•© ì •ë°€ë„ í›ˆë ¨**: `torch.cuda.amp` ì‚¬ìš©ìœ¼ë¡œ FP16 í›ˆë ¨
- **ë©”ëª¨ë¦¬ í™œìš©**: 40GB+ ë©”ëª¨ë¦¬ í™œìš©í•œ ë°°ì¹˜ ì‚¬ì´ì¦ˆ 256
- **GPU ì„¤ì •**: `cudnn.benchmark = True`, ë©”ëª¨ë¦¬ ë¶„í•  95%

### **3. ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”**
- **Fallback ë©”ì»¤ë‹ˆì¦˜**: ì‹œí€€ìŠ¤ ëª¨ë¸ ì‹¤íŒ¨ ì‹œ í…Œì´ë¸” ëª¨ë¸ë§Œ ì‹¤í–‰
- **ë‹¨ê³„ë³„ ê²€ì¦**: ê° ë‹¨ê³„ë§ˆë‹¤ ë°ì´í„° í’ˆì§ˆ í™•ì¸
- **ìƒì„¸í•œ ë¡œê¹…**: ë¬¸ì œ ë°œìƒ ì§€ì  ëª…í™•íˆ íŒŒì•…

## ğŸ”§ **ì¦‰ì‹œ ì ìš©í•  ìˆ˜ì •ì‚¬í•­**

### **ê¸°ì¡´ ë…¸íŠ¸ë¶ì—ì„œ ìˆ˜ì •í•  ë¶€ë¶„**

#### **1. ë°ì´í„° ë¡œë”© ì…€ ìˆ˜ì •**
```python
# âŒ ê¸°ì¡´ ì½”ë“œ (ì˜¤ë¥˜ ë°œìƒ)
def prepare_sequence_data():
    # ... ê¸°ì¡´ ì½”ë“œ ...

# âœ… ìˆ˜ì •ëœ ì½”ë“œ
def prepare_sequence_data_fixed(metadata):
    """A100 GPU ìµœì í™”ëœ ì‹œí€€ìŠ¤ ë°ì´í„° ì¤€ë¹„ (ë¬¸ìì—´ ì˜¤ë¥˜ í•´ê²°)"""
    
    try:
        # Load sequence data
        timestamp = metadata['timestamp']
        sequences_data = np.load(f'sequences_{timestamp}.npz')
        
        print(f"ğŸ” Loading sequence data: {timestamp}")
        
        all_sequences = []
        all_targets = []
        all_dates = []
        
        # ë°ì´í„° íƒ€ì… ê°•ì œ ë³€í™˜ ë° ë¬¸ìì—´ ì œê±°
        for ticker in metadata['tickers']:
            if f'{ticker}_sequences' in sequences_data:
                sequences = sequences_data[f'{ticker}_sequences']
                targets = sequences_data[f'{ticker}_targets_1d']
                dates = sequences_data[f'{ticker}_dates']
                
                print(f"   Processing {ticker}: {sequences.shape}, dtype: {sequences.dtype}")
                
                # ë¬¸ìì—´ì´ í¬í•¨ëœ ê²½ìš° ìˆ«ì ì»¬ëŸ¼ë§Œ ì„ íƒ
                if sequences.dtype == object:
                    print(f"   âš ï¸ {ticker} has object dtype, cleaning...")
                    
                    numeric_cols = []
                    for i in range(sequences.shape[2]):
                        try:
                            # ê° ì»¬ëŸ¼ì„ floatë¡œ ë³€í™˜ ì‹œë„
                            test_col = sequences[:, :, i].astype(float)
                            numeric_cols.append(i)
                        except:
                            continue
                    
                    if len(numeric_cols) > 0:
                        sequences = sequences[:, :, numeric_cols].astype(np.float32)
                        print(f"   âœ… {ticker}: {len(numeric_cols)} numeric columns extracted")
                    else:
                        print(f"   âŒ {ticker}: No numeric columns found, skipping")
                        continue
                else:
                    sequences = sequences.astype(np.float32)
                
                # NaN ê°’ ì²˜ë¦¬
                if np.any(np.isnan(sequences)) or np.any(np.isinf(sequences)):
                    print(f"   ğŸ§¹ {ticker}: Cleaning NaN/Inf values...")
                    sequences = np.nan_to_num(sequences, nan=0.0, posinf=0.0, neginf=0.0)
                
                all_sequences.append(sequences)
                all_targets.extend(targets)
                all_dates.extend(dates)
        
        if not all_sequences:
            raise ValueError("âŒ No valid numeric sequences found!")
        
        # A100 ìµœì í™”: float32 ì‚¬ìš©
        X_seq = np.vstack(all_sequences).astype(np.float32)
        y_seq = np.array(all_targets, dtype=np.float32)
        
        print(f"âœ… Sequence data prepared: {X_seq.shape}, dtype: {X_seq.dtype}")
        return X_seq, y_seq, all_dates
        
    except Exception as e:
        print(f"âŒ Error preparing sequence data: {e}")
        print("ğŸ”§ Fallback to tabular models only...")
        return None, None, None
```

#### **2. A100 GPU ìµœì í™” ì„¤ì • ì¶”ê°€**
```python
# GPU ì„¤ì • ì…€ì— ì¶”ê°€
import torch

# A100 GPU ìµœì í™”
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
if device.type == 'cuda':
    print(f"ğŸš€ Using GPU: {torch.cuda.get_device_name(0)}")
    print(f"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    
    # A100 ìµœì í™” ì„¤ì •
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = False
    
    # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± (A100 ë©”ëª¨ë¦¬ 40GB+ í™œìš©)
    torch.cuda.set_per_process_memory_fraction(0.95)
    
    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
    torch.cuda.empty_cache()
else:
    print("ğŸ’» Using CPU")

# í˜¼í•© ì •ë°€ë„ í›ˆë ¨ (FP16)
from torch.cuda.amp import autocast, GradScaler
scaler = GradScaler()
```

#### **3. LSTM í›ˆë ¨ í•¨ìˆ˜ ìˆ˜ì •**
```python
# LSTM í›ˆë ¨ í•¨ìˆ˜ ìˆ˜ì •
def train_lstm(X_train, y_train, X_val, y_val, epochs=100, batch_size=256, lr=0.001):
    """A100 GPU ìµœì í™”ëœ LSTM í›ˆë ¨"""
    
    input_size = X_train.shape[2]
    model = LSTMModel(input_size).to(device)
    criterion = nn.MSELoss()
    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)
    
    # A100 ìµœì í™”: í˜¼í•© ì •ë°€ë„ í›ˆë ¨
    scaler = GradScaler()
    
    # Create data loaders with larger batch size
    train_dataset = TensorDataset(
        torch.FloatTensor(X_train),
        torch.FloatTensor(y_train)
    )
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    
    val_dataset = TensorDataset(
        torch.FloatTensor(X_val),
        torch.FloatTensor(y_val)
    )
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    
    # ... ë‚˜ë¨¸ì§€ í›ˆë ¨ ë¡œì§ ...
```

## ğŸš€ **ì‹¤í–‰ ìˆœì„œ**

### **1ë‹¨ê³„: ë°ì´í„° ì—…ë¡œë“œ**
```python
from google.colab import files

print("ğŸ“¤ Upload the following files:")
print("   - tabular_train_YYYYMMDD_HHMMSS.csv")
print("   - tabular_val_YYYYMMDD_HHMMSS.csv") 
print("   - tabular_test_YYYYMMDD_HHMMSS.csv")
print("   - sequences_YYYYMMDD_HHMMSS.npz")
print("   - dataset_metadata_YYYYMMDD_HHMMSS.json")

uploaded = files.upload()
```

### **2ë‹¨ê³„: ë°ì´í„° ë¡œë”© ë° ê²€ì¦**
```python
# ê°•í™”ëœ ë°ì´í„° ë¡œë”©
train_df, val_df, test_df, metadata = load_data_robust()

# ì‹œí€€ìŠ¤ ë°ì´í„° ì¤€ë¹„ (ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨)
X_seq, y_seq, dates_seq = prepare_sequence_data_fixed(metadata)

if X_seq is not None:
    # ì°¨ì› ê²€ì¦
    if validate_sequence_dimensions(X_seq, y_seq):
        USE_SEQUENCE_MODELS = True
        print("âœ… Sequence models enabled")
    else:
        USE_SEQUENCE_MODELS = False
        print("âš ï¸ Sequence models disabled")
else:
    USE_SEQUENCE_MODELS = False
    print("âš ï¸ Sequence models disabled")
```

### **3ë‹¨ê³„: ëª¨ë¸ í›ˆë ¨**
```python
# MLP ëª¨ë¸ (í•­ìƒ ì‹¤í–‰)
mlp_model = train_mlp_a100(X_train, y_train, X_val, y_val, device)

# LSTM ëª¨ë¸ (ì‹œí€€ìŠ¤ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ)
if USE_SEQUENCE_MODELS:
    lstm_model = train_lstm_a100(X_train_seq, y_train_seq, X_val_seq, y_val_seq, device)
```

## ğŸ“Š **ì˜ˆìƒ ê²°ê³¼**

### **ì„±ê³µ ì‹œë‚˜ë¦¬ì˜¤**
- **LSTM ë°ì´í„° ë¡œë”©**: ë¬¸ìì—´ ì˜¤ë¥˜ ì—†ì´ ì •ìƒ ë¡œë”©
- **ëª¨ë¸ í›ˆë ¨**: A100 GPU í™œìš©í•œ ë¹ ë¥¸ í›ˆë ¨
- **ì„±ëŠ¥ í–¥ìƒ**: IC â‰¥ 0.03 ë‹¬ì„± ê°€ëŠ¥ì„± ë†’ìŒ

### **ì‹¤íŒ¨ ì‹œë‚˜ë¦¬ì˜¤ (Fallback)**
- **ì‹œí€€ìŠ¤ ëª¨ë¸ ë¹„í™œì„±í™”**: í…Œì´ë¸” ëª¨ë¸ë§Œ ì‹¤í–‰
- **ì•ˆì •ì ì¸ ì‹¤í–‰**: ì˜¤ë¥˜ ì—†ì´ ì™„ë£Œ
- **ê¸°ë³¸ ì„±ëŠ¥**: ê¸°ì¡´ Traditional ML ìˆ˜ì¤€ ìœ ì§€

## ğŸ” **ë¬¸ì œ í•´ê²° ì²´í¬ë¦¬ìŠ¤íŠ¸**

### **LSTM ë°ì´í„° ë¡œë”© ë¬¸ì œ**
- [ ] `sequences.dtype == object` ê²€ì‚¬
- [ ] ìˆ«ì ì»¬ëŸ¼ë§Œ ì¶”ì¶œí•˜ëŠ” ë¡œì§
- [ ] NaN/Inf ê°’ ì²˜ë¦¬
- [ ] ì°¨ì› ê²€ì¦ (3D ë°°ì—´ í™•ì¸)

### **A100 GPU ìµœì í™”**
- [ ] í˜¼í•© ì •ë°€ë„ í›ˆë ¨ (FP16)
- [ ] ë°°ì¹˜ ì‚¬ì´ì¦ˆ 256ìœ¼ë¡œ ì¦ê°€
- [ ] GPU ë©”ëª¨ë¦¬ ì„¤ì • (95% í™œìš©)
- [ ] `cudnn.benchmark = True`

### **ì˜¤ë¥˜ ì²˜ë¦¬**
- [ ] Fallback ë©”ì»¤ë‹ˆì¦˜ êµ¬í˜„
- [ ] ë‹¨ê³„ë³„ ê²€ì¦ ë¡œì§
- [ ] ìƒì„¸í•œ ì—ëŸ¬ ë¡œê¹…
- [ ] ì•ˆì „í•œ ë°ì´í„° íƒ€ì… ë³€í™˜

## ğŸ’¡ **í•µì‹¬ íŒ**

1. **ë¬¸ìì—´ ë°ì´í„°**: `sequences.dtype == object` ì¼ ë•Œë§Œ íŠ¹ë³„ ì²˜ë¦¬
2. **ë©”ëª¨ë¦¬ ê´€ë¦¬**: A100 ë©”ëª¨ë¦¬ 40GB+ í™œìš©í•˜ì—¬ ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¦ê°€
3. **í˜¼í•© ì •ë°€ë„**: FP16 í›ˆë ¨ìœ¼ë¡œ ì†ë„ì™€ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ
4. **Fallback**: ì‹œí€€ìŠ¤ ëª¨ë¸ ì‹¤íŒ¨ ì‹œ í…Œì´ë¸” ëª¨ë¸ë¡œ ê³„ì† ì§„í–‰

ì´ ê°€ì´ë“œë¥¼ ë”°ë¼ ìˆ˜ì •í•˜ë©´ A100ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ì‹¤í–‰ë˜ê³  LSTM ë°ì´í„° ë¡œë”© ë¬¸ì œë„ ì™„ì „íˆ í•´ê²°ë  ê²ƒì…ë‹ˆë‹¤!
