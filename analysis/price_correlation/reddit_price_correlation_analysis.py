#!/usr/bin/env python3
"""
Reddit mentions and price correlation analysis & visualization

Analyzes relationship between Reddit mentions and price movements in meme stocks.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# Font settings for compatibility
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

def load_data():
    """Load data efficiently"""
    print("Loading data...")
    
    # Load data with optimal dtypes for memory efficiency
    dtype_dict = {
        'ticker': 'category',
        'returns_1d': 'float32', 
        'returns_5d': 'float32',
        'vol_5d': 'float32',
        'log_mentions': 'float32',
        'rsi_14': 'float32',
        'volume_ratio': 'float32',
        'reddit_ema_3': 'float32',
        'reddit_momentum_7': 'float32',
        'reddit_surprise': 'float32',
        'market_sentiment': 'float32'
    }
    
    # Load only essential columns
    cols_needed = ['date', 'ticker', 'log_mentions', 'returns_1d', 'returns_5d', 
                   'vol_5d', 'rsi_14', 'volume_ratio', 'reddit_ema_3', 
                   'reddit_momentum_7', 'reddit_surprise', 'market_sentiment']
    
    print("Loading train data...")
    train_df = pd.read_csv('data/colab_datasets/tabular_train_20250814_031335.csv', 
                          usecols=cols_needed, dtype=dtype_dict)
    print("Loading validation data...")
    val_df = pd.read_csv('data/colab_datasets/tabular_val_20250814_031335.csv',
                        usecols=cols_needed, dtype=dtype_dict)
    print("Loading test data...")
    test_df = pd.read_csv('data/colab_datasets/tabular_test_20250814_031335.csv',
                         usecols=cols_needed, dtype=dtype_dict)
    
    # Combine data
    df = pd.concat([train_df, val_df, test_df], ignore_index=True)
    del train_df, val_df, test_df  # Free memory
    
    # Convert date efficiently
    df['date'] = pd.to_datetime(df['date'])
    
    print(f"Data loaded: {len(df)} samples")
    print(f"Period: {df['date'].min()} ~ {df['date'].max()}")
    print(f"Tickers: {df['ticker'].unique()}")
    print(f"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
    
    return df

def analyze_ticker_correlations_fast(df):
    """Fast ticker-specific correlation analysis"""
    print("\nAnalyzing ticker correlations...")
    
    # log_mentions ë¶„í¬
    plt.figure(figsize=(15, 10))
    
    # 1. ì „ì²´ ë¶„í¬
    plt.subplot(2, 3, 1)
    plt.hist(df['log_mentions'].dropna(), bins=50, alpha=0.7, color='skyblue', edgecolor='black')
    plt.title('ì „ì²´ Log Mentions ë¶„í¬')
    plt.xlabel('Log Mentions')
    plt.ylabel('ë¹ˆë„')
    plt.axvline(df['log_mentions'].median(), color='red', linestyle='--', label=f'ì¤‘ì•™ê°’: {df["log_mentions"].median():.2f}')
    plt.legend()
    
    # 2. í‹°ì»¤ë³„ ë¶„í¬
    plt.subplot(2, 3, 2)
    df.boxplot(column='log_mentions', by='ticker', ax=plt.gca())
    plt.title('í‹°ì»¤ë³„ Log Mentions ë¶„í¬')
    plt.suptitle('')  # boxplotì˜ ê¸°ë³¸ ì œëª© ì œê±°
    
    # 3. ì–¸ê¸‰ ìˆ˜ í†µê³„
    plt.subplot(2, 3, 3)
    mentions_stats = df.groupby('ticker')['log_mentions'].agg(['mean', 'std', 'min', 'max']).round(2)
    plt.table(cellText=mentions_stats.values, 
              rowLabels=mentions_stats.index,
              colLabels=mentions_stats.columns,
              cellLoc='center',
              loc='center')
    plt.title('í‹°ì»¤ë³„ ì–¸ê¸‰ ìˆ˜ í†µê³„')
    plt.axis('off')
    
    # 4. ì‹œê°„ë³„ ì–¸ê¸‰ ìˆ˜ ë³€í™”
    plt.subplot(2, 3, 4)
    daily_mentions = df.groupby('date')['log_mentions'].mean()
    plt.plot(daily_mentions.index, daily_mentions.values, alpha=0.7, linewidth=1)
    plt.title('ì¼ë³„ í‰ê·  ì–¸ê¸‰ ìˆ˜ ë³€í™”')
    plt.xlabel('ë‚ ì§œ')
    plt.ylabel('í‰ê·  Log Mentions')
    plt.xticks(rotation=45)
    
    # 5. ì–¸ê¸‰ ìˆ˜ vs ìˆ˜ìµë¥  ì‚°ì ë„
    plt.subplot(2, 3, 5)
    plt.scatter(df['log_mentions'], df['returns_1d'], alpha=0.5, s=1)
    plt.title('ì–¸ê¸‰ ìˆ˜ vs 1ì¼ ìˆ˜ìµë¥ ')
    plt.xlabel('Log Mentions')
    plt.ylabel('Returns (1d)')
    
    # 6. ì–¸ê¸‰ ìˆ˜ vs ë³€ë™ì„±
    plt.subplot(2, 3, 6)
    plt.scatter(df['log_mentions'], df['vol_5d'], alpha=0.5, s=1)
    plt.title('ì–¸ê¸‰ ìˆ˜ vs 5ì¼ ë³€ë™ì„±')
    plt.xlabel('Log Mentions')
    plt.ylabel('Volatility (5d)')
    
    plt.tight_layout()
    plt.savefig('mentions_distribution_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return mentions_stats

def analyze_correlations(df):
    """ìƒê´€ê´€ê³„ ë¶„ì„"""
    print("\nğŸ”— ìƒê´€ê´€ê³„ ë¶„ì„...")
    
    # ì£¼ìš” ë³€ìˆ˜ë“¤ ì„ íƒ
    key_vars = [
        'log_mentions',           # Reddit ì–¸ê¸‰ ìˆ˜
        'returns_1d',            # 1ì¼ ìˆ˜ìµë¥ 
        'returns_5d',            # 5ì¼ ìˆ˜ìµë¥ 
        'vol_5d',                # 5ì¼ ë³€ë™ì„±
        'rsi_14',                # RSI
        'volume_ratio',          # ê±°ë˜ëŸ‰ ë¹„ìœ¨
        'reddit_ema_3',          # Reddit EMA 3ì¼
        'reddit_momentum_7',     # Reddit ëª¨ë©˜í…€ 7ì¼
        'reddit_surprise',       # Reddit ì„œí”„ë¼ì´ì¦ˆ
        'market_sentiment'       # ì‹œì¥ ê°ì •
    ]
    
    # ìƒê´€ê´€ê³„ ê³„ì‚°
    corr_matrix = df[key_vars].corr()
    
    # ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
    plt.figure(figsize=(12, 10))
    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
    sns.heatmap(corr_matrix, 
                mask=mask,
                annot=True, 
                cmap='RdBu_r', 
                center=0,
                square=True,
                fmt='.3f',
                cbar_kws={'shrink': 0.8})
    plt.title('ì£¼ìš” ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ')
    plt.tight_layout()
    plt.savefig('correlation_heatmap.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return corr_matrix

def analyze_lag_correlations(df):
    """ì§€ì—° ìƒê´€ê´€ê³„ ë¶„ì„ (ì–¸ê¸‰ ìˆ˜ê°€ ë¯¸ë˜ ìˆ˜ìµë¥ ì— ë¯¸ì¹˜ëŠ” ì˜í–¥)"""
    print("\nâ° ì§€ì—° ìƒê´€ê´€ê³„ ë¶„ì„...")
    
    # ì§€ì—° ê¸°ê°„ ì„¤ì •
    lags = [0, 1, 2, 3, 5, 7]
    lag_correlations = []
    
    for lag in lags:
        if lag == 0:
            # ë™ì‹œ ìƒê´€ê´€ê³„
            # NaN ì œê±°í•˜ê³  ê°™ì€ ì¸ë±ìŠ¤ë¡œ ë§ì¶¤
            valid_data = df[['log_mentions', 'returns_1d']].dropna()
            corr = valid_data['log_mentions'].corr(valid_data['returns_1d'])
            
            lag_correlations.append({
                'lag': lag,
                'correlation': corr,
                'p_value': stats.pearsonr(valid_data['log_mentions'], valid_data['returns_1d'])[1]
            })
        else:
            # ì§€ì—° ìƒê´€ê´€ê³„ (ì–¸ê¸‰ ìˆ˜ê°€ ë¯¸ë˜ ìˆ˜ìµë¥ ì— ë¯¸ì¹˜ëŠ” ì˜í–¥)
            df_lag = df.copy()
            df_lag[f'returns_lag_{lag}'] = df_lag.groupby('ticker')['returns_1d'].shift(-lag)
            
            # NaN ì œê±°
            valid_data = df_lag[['log_mentions', f'returns_lag_{lag}']].dropna()
            
            if len(valid_data) > 10:  # ìµœì†Œ ë°ì´í„° ìˆ˜ í™•ì¸
                corr = valid_data['log_mentions'].corr(valid_data[f'returns_lag_{lag}'])
                p_val = stats.pearsonr(valid_data['log_mentions'], valid_data[f'returns_lag_{lag}'])[1]
                
                lag_correlations.append({
                    'lag': lag,
                    'correlation': corr,
                    'p_value': p_val
                })
    
    # ê²°ê³¼ ì‹œê°í™”
    lag_df = pd.DataFrame(lag_correlations)
    
    plt.figure(figsize=(12, 8))
    
    # 1. ì§€ì—° ìƒê´€ê´€ê³„ ê·¸ë˜í”„
    plt.subplot(2, 2, 1)
    plt.plot(lag_df['lag'], lag_df['correlation'], 'o-', linewidth=2, markersize=8)
    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    plt.title('ì–¸ê¸‰ ìˆ˜ì™€ ë¯¸ë˜ ìˆ˜ìµë¥ ì˜ ì§€ì—° ìƒê´€ê´€ê³„')
    plt.xlabel('ì§€ì—° ê¸°ê°„ (ì¼)')
    plt.ylabel('ìƒê´€ê³„ìˆ˜')
    plt.grid(True, alpha=0.3)
    
    # 2. P-value ê·¸ë˜í”„
    plt.subplot(2, 2, 2)
    plt.plot(lag_df['lag'], lag_df['p_value'], 'o-', linewidth=2, markersize=8, color='red')
    plt.axhline(y=0.05, color='black', linestyle='--', alpha=0.5, label='p=0.05')
    plt.title('ì§€ì—° ìƒê´€ê´€ê³„ì˜ í†µê³„ì  ìœ ì˜ì„±')
    plt.xlabel('ì§€ì—° ê¸°ê°„ (ì¼)')
    plt.ylabel('P-value')
    plt.yscale('log')
    plt.grid(True, alpha=0.3)
    plt.legend()
    
    # 3. ìƒê´€ê´€ê³„ vs P-value
    plt.subplot(2, 2, 3)
    plt.scatter(lag_df['correlation'], lag_df['p_value'], s=100, alpha=0.7)
    for i, row in lag_df.iterrows():
        plt.annotate(f"lag={row['lag']}", (row['correlation'], row['p_value']), 
                    xytext=(5, 5), textcoords='offset points')
    plt.axhline(y=0.05, color='red', linestyle='--', alpha=0.5)
    plt.title('ìƒê´€ê³„ìˆ˜ vs P-value')
    plt.xlabel('ìƒê´€ê³„ìˆ˜')
    plt.ylabel('P-value')
    plt.grid(True, alpha=0.3)
    
    # 4. ê²°ê³¼ í…Œì´ë¸”
    plt.subplot(2, 2, 4)
    plt.axis('off')
    table_data = lag_df.round(4)
    table = plt.table(cellText=table_data.values,
                     colLabels=table_data.columns,
                     cellLoc='center',
                     loc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 2)
    plt.title('ì§€ì—° ìƒê´€ê´€ê³„ ê²°ê³¼ ìš”ì•½')
    
    plt.tight_layout()
    plt.savefig('lag_correlation_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return lag_df

def analyze_ticker_specific_correlations(df):
    """í‹°ì»¤ë³„ ìƒê´€ê´€ê³„ ë¶„ì„"""
    print("\nğŸ¯ í‹°ì»¤ë³„ ìƒê´€ê´€ê³„ ë¶„ì„...")
    
    tickers = df['ticker'].unique()
    ticker_correlations = []
    
    for ticker in tickers:
        ticker_data = df[df['ticker'] == ticker]
        
        if len(ticker_data) > 50:  # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ
            # ì–¸ê¸‰ ìˆ˜ì™€ ìˆ˜ìµë¥ ì˜ ìƒê´€ê´€ê³„
            corr_1d = ticker_data['log_mentions'].corr(ticker_data['returns_1d'])
            corr_5d = ticker_data['log_mentions'].corr(ticker_data['returns_5d'])
            
            # ì–¸ê¸‰ ìˆ˜ì™€ ë³€ë™ì„±ì˜ ìƒê´€ê´€ê³„
            corr_vol = ticker_data['log_mentions'].corr(ticker_data['vol_5d'])
            
            ticker_correlations.append({
                'ticker': ticker,
                'mentions_returns_1d': corr_1d,
                'mentions_returns_5d': corr_5d,
                'mentions_volatility': corr_vol,
                'sample_size': len(ticker_data)
            })
    
    ticker_corr_df = pd.DataFrame(ticker_correlations)
    
    # ì‹œê°í™”
    plt.figure(figsize=(15, 10))
    
    # 1. í‹°ì»¤ë³„ ì–¸ê¸‰ ìˆ˜-ìˆ˜ìµë¥  ìƒê´€ê´€ê³„
    plt.subplot(2, 3, 1)
    bars = plt.bar(ticker_corr_df['ticker'], ticker_corr_df['mentions_returns_1d'])
    plt.title('í‹°ì»¤ë³„: ì–¸ê¸‰ ìˆ˜ vs 1ì¼ ìˆ˜ìµë¥  ìƒê´€ê´€ê³„')
    plt.xlabel('í‹°ì»¤')
    plt.ylabel('ìƒê´€ê³„ìˆ˜')
    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    
    # ìƒ‰ìƒ ì„¤ì • (ì–‘ìˆ˜/ìŒìˆ˜)
    for bar in bars:
        if bar.get_height() > 0:
            bar.set_color('green')
        else:
            bar.set_color('red')
    
    # 2. í‹°ì»¤ë³„ ì–¸ê¸‰ ìˆ˜-5ì¼ ìˆ˜ìµë¥  ìƒê´€ê´€ê³„
    plt.subplot(2, 3, 2)
    bars = plt.bar(ticker_corr_df['ticker'], ticker_corr_df['mentions_returns_5d'])
    plt.title('í‹°ì»¤ë³„: ì–¸ê¸‰ ìˆ˜ vs 5ì¼ ìˆ˜ìµë¥  ìƒê´€ê´€ê³„')
    plt.xlabel('í‹°ì»¤')
    plt.ylabel('ìƒê´€ê³„ìˆ˜')
    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    
    for bar in bars:
        if bar.get_height() > 0:
            bar.set_color('green')
        else:
            bar.set_color('red')
    
    # 3. í‹°ì»¤ë³„ ì–¸ê¸‰ ìˆ˜-ë³€ë™ì„± ìƒê´€ê´€ê³„
    plt.subplot(2, 3, 3)
    bars = plt.bar(ticker_corr_df['ticker'], ticker_corr_df['mentions_volatility'])
    plt.title('í‹°ì»¤ë³„: ì–¸ê¸‰ ìˆ˜ vs ë³€ë™ì„± ìƒê´€ê´€ê³„')
    plt.xlabel('í‹°ì»¤')
    plt.ylabel('ìƒê´€ê³„ìˆ˜')
    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    
    for bar in bars:
        if bar.get_height() > 0:
            bar.set_color('green')
        else:
            bar.set_color('red')
    
    # 4. ìƒê´€ê´€ê³„ ë¹„êµ
    plt.subplot(2, 3, 4)
    x = np.arange(len(ticker_corr_df))
    width = 0.25
    
    plt.bar(x - width, ticker_corr_df['mentions_returns_1d'], width, label='1ì¼ ìˆ˜ìµë¥ ', alpha=0.8)
    plt.bar(x, ticker_corr_df['mentions_returns_5d'], width, label='5ì¼ ìˆ˜ìµë¥ ', alpha=0.8)
    plt.bar(x + width, ticker_corr_df['mentions_volatility'], width, label='ë³€ë™ì„±', alpha=0.8)
    
    plt.title('í‹°ì»¤ë³„ ìƒê´€ê´€ê³„ ë¹„êµ')
    plt.xlabel('í‹°ì»¤')
    plt.ylabel('ìƒê´€ê³„ìˆ˜')
    plt.xticks(x, ticker_corr_df['ticker'])
    plt.legend()
    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    
    # 5. ìƒ˜í”Œ í¬ê¸°
    plt.subplot(2, 3, 5)
    plt.bar(ticker_corr_df['ticker'], ticker_corr_df['sample_size'])
    plt.title('í‹°ì»¤ë³„ ìƒ˜í”Œ í¬ê¸°')
    plt.xlabel('í‹°ì»¤')
    plt.ylabel('ìƒ˜í”Œ ìˆ˜')
    
    # 6. ê²°ê³¼ ìš”ì•½ í…Œì´ë¸”
    plt.subplot(2, 3, 6)
    plt.axis('off')
    summary_data = ticker_corr_df.round(4)
    table = plt.table(cellText=summary_data.values,
                     colLabels=summary_data.columns,
                     cellLoc='center',
                     loc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(8)
    table.scale(1, 2)
    plt.title('í‹°ì»¤ë³„ ìƒê´€ê´€ê³„ ìš”ì•½')
    
    plt.tight_layout()
    plt.savefig('ticker_specific_correlations.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return ticker_corr_df

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Reddit ì–¸ê¸‰ ìˆ˜ì™€ ê°€ê²© ìƒê´€ê´€ê³„ ë¶„ì„ ì‹œì‘")
    print("=" * 60)
    
    # 1. ë°ì´í„° ë¡œë”©
    df = load_data()
    
    # 2. ì–¸ê¸‰ ìˆ˜ ë¶„í¬ ë¶„ì„
    mentions_stats = analyze_mentions_distribution(df)
    
    # 3. ìƒê´€ê´€ê³„ ë¶„ì„
    corr_matrix = analyze_correlations(df)
    
    # 4. ì§€ì—° ìƒê´€ê´€ê³„ ë¶„ì„
    lag_correlations = analyze_lag_correlations(df)
    
    # 5. í‹°ì»¤ë³„ ìƒê´€ê´€ê³„ ë¶„ì„
    ticker_correlations = analyze_ticker_specific_correlations(df)
    
    # 6. ê²°ê³¼ ìš”ì•½
    print("\nğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    
    print(f"ì–¸ê¸‰ ìˆ˜ì™€ 1ì¼ ìˆ˜ìµë¥  ìƒê´€ê´€ê³„: {df['log_mentions'].corr(df['returns_1d']):.4f}")
    print(f"ì–¸ê¸‰ ìˆ˜ì™€ 5ì¼ ìˆ˜ìµë¥  ìƒê´€ê´€ê³„: {df['log_mentions'].corr(df['returns_5d']):.4f}")
    print(f"ì–¸ê¸‰ ìˆ˜ì™€ ë³€ë™ì„± ìƒê´€ê´€ê³„: {df['log_mentions'].corr(df['vol_5d']):.4f}")
    
    print(f"\nê°€ì¥ ë†’ì€ ì§€ì—° ìƒê´€ê´€ê³„:")
    best_lag = lag_correlations.loc[lag_correlations['correlation'].abs().idxmax()]
    print(f"  ì§€ì—° {best_lag['lag']}ì¼: {best_lag['correlation']:.4f} (p={best_lag['p_value']:.4f})")
    
    print(f"\ní‹°ì»¤ë³„ ìµœê³  ìƒê´€ê´€ê³„:")
    best_ticker = ticker_correlations.loc[ticker_correlations['mentions_returns_1d'].abs().idxmax()]
    print(f"  {best_ticker['ticker']}: {best_ticker['mentions_returns_1d']:.4f}")
    
    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ! ì‹œê°í™” íŒŒì¼ë“¤ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("   - mentions_distribution_analysis.png")
    print("   - correlation_heatmap.png")
    print("   - lag_correlation_analysis.png")
    print("   - ticker_specific_correlations.png")

if __name__ == "__main__":
    main()
